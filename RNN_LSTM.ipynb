{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7acFEAzytM2",
        "outputId": "e527a9f8-3601-419b-bbd6-ad547394fa9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pythainlp\n",
            "  Downloading pythainlp-5.1.0-py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.11/dist-packages (from pythainlp) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->pythainlp) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->pythainlp) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->pythainlp) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31->pythainlp) (2025.1.31)\n",
            "Downloading pythainlp-5.1.0-py3-none-any.whl (19.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.3/19.3 MB\u001b[0m \u001b[31m85.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pythainlp\n",
            "Successfully installed pythainlp-5.1.0\n"
          ]
        }
      ],
      "source": [
        "pip install pythainlp\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_j-ca6Pfy5J4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "# from nltk.tokenize import word_tokenize\n",
        "from pythainlp.tokenize import word_tokenize\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, GRU, LSTM, Bidirectional, Embedding, Dropout, BatchNormalization\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pickle as p\n",
        "import plotly\n",
        "import plotly.graph_objs as go\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6YsBlejWeoK"
      },
      "source": [
        "import aiohttp\n",
        "import asyncio\n",
        "\n",
        "API_SENTIMENT_URL = \"https://api.aiforthai.in.th/ssense\"\n",
        "API_BULLY_URL = \"https://api.aiforthai.in.th/bully\"\n",
        "API_KEY = \"MLmi4VDme8ONK91lcqSUkc90vqqK7TgU\"\n",
        "\n",
        "RETRY_DELAY = 3\n",
        "MAX_RETRIES = 10\n",
        "\n",
        "async def analyze_sentiment(session, comment):\n",
        "    \"\"\"วิเคราะห์ sentiment (pos, neu, neg)\"\"\"\n",
        "    headers = {\"Apikey\": API_KEY}\n",
        "    params = {\"text\": comment}\n",
        "\n",
        "    for _ in range(MAX_RETRIES):\n",
        "        try:\n",
        "            async with session.get(API_SENTIMENT_URL, headers=headers, params=params) as response:\n",
        "                if response.status == 200:\n",
        "                    result = await response.json()\n",
        "                    sentiment = result.get(\"sentiment\", {}).get(\"polarity\", \"neutral\")\n",
        "                    return sentiment[:3] if sentiment in [\"positive\", \"negative\", \"neutral\"] else \"neu\"\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error in sentiment API: {e}\")\n",
        "        await asyncio.sleep(RETRY_DELAY)\n",
        "\n",
        "    return \"neu\"\n",
        "\n",
        "async def analyze_bully(session, comment):\n",
        "    \"\"\"ตรวจสอบคำหยาบและบูลลี่\"\"\"\n",
        "    headers = {\"Apikey\": API_KEY}\n",
        "    params = {\"text\": comment}\n",
        "\n",
        "    for _ in range(MAX_RETRIES):\n",
        "        try:\n",
        "            async with session.get(API_BULLY_URL, headers=headers, params=params) as response:\n",
        "                if response.status == 200:\n",
        "                    result = await response.json()\n",
        "                    bully_type = result.get(\"bully_type\", [])\n",
        "\n",
        "                    if not bully_type or 0 in bully_type:\n",
        "                        return \"neg\"\n",
        "\n",
        "                    if any(bt in [2, 6] for bt in bully_type):  # คำหยาบ, ข่มขู่\n",
        "                        return \"hig\"\n",
        "\n",
        "                    if any(bt in [1, 3, 4, 5] for bt in bully_type):  # บูลลี่\n",
        "                        return \"bly\"\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error in bully API: {e}\")\n",
        "        await asyncio.sleep(RETRY_DELAY)\n",
        "\n",
        "    return \"neg\"\n",
        "\n",
        "async def analyze_comment(session, comment):\n",
        "    \"\"\"รวมการวิเคราะห์ sentiment และคำหยาบ\"\"\"\n",
        "    sentiment = await analyze_sentiment(session, comment)\n",
        "\n",
        "    if sentiment == \"neg\":\n",
        "        return await analyze_bully(session, comment)\n",
        "    return sentiment\n",
        "\n",
        "async def process_comments():\n",
        "    \"\"\"อ่านไฟล์ train.txt และวิเคราะห์ข้อความ\"\"\"\n",
        "    label_counts = {\"pos\": 0, \"neu\": 0, \"neg\": 0, \"hig\": 0, \"bly\": 0}\n",
        "\n",
        "    with open(\"train.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "        comments = [line.strip() for line in file if line.strip()]\n",
        "\n",
        "    async with aiohttp.ClientSession() as session:\n",
        "        tasks = [analyze_comment(session, comment) for comment in comments]\n",
        "        results = await asyncio.gather(*tasks)\n",
        "\n",
        "    with open(\"train_label.txt\", \"w\", encoding=\"utf-8\") as file:\n",
        "        for result in results:\n",
        "            file.write(f\"{result}\\n\")\n",
        "            if result in label_counts:\n",
        "                label_counts[result] += 1\n",
        "\n",
        "    print(f\"✅ วิเคราะห์เสร็จแล้ว! ผลลัพธ์บันทึกที่ train_label.txt\")\n",
        "    for label, count in label_counts.items():\n",
        "        print(f\"จำนวน {label}: {count} คำ\")\n",
        "\n",
        "# รันโปรแกรม\n",
        "await process_comments()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i1zLWP5ky55d"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 300\n",
        "BS = 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TgGJ3zwJz40X"
      },
      "outputs": [],
      "source": [
        "comments = []\n",
        "labels = []\n",
        "\n",
        "with open(\"train_cleaned.txt\",encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        comments.append(line.strip())\n",
        "\n",
        "with open(\"train_label (3).txt\",encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        labels.append(line.strip())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2kdB84yX50w",
        "outputId": "4dca885a-f992-45b1-e58b-7c7389f89667"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "63456 63456\n"
          ]
        }
      ],
      "source": [
        "print(len(comments), len(labels))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Qg3pVZxH0Vfd",
        "outputId": "605028bb-a33e-42b7-c84b-ec2a09a69730"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 63456,\n  \"fields\": [\n    {\n      \"column\": \"category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"neu\",\n          \"hig\",\n          \"neg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"comments\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 59201,\n        \"samples\": [\n          \"\\u0e0a\\u0e34\\u0e1b\\u0e2b\\u0e32\\u0e22\\u0e25\\u0e30\\u0e04\\u0e23\\u0e31\\u0e1a\",\n          \"\\u0e41\\u0e09\\u0e2a\\u0e48\\u0e27\\u0e22 \\u0e15\\u0e48\\u0e2d\\u0e43\\u0e2b\\u0e49\\u0e1e\\u0e22\\u0e32\\u0e22\\u0e32\\u0e21\\u0e41\\u0e04\\u0e48\\u0e44\\u0e2b\\u0e19 \\u0e15\\u0e33\\u0e23\\u0e27\\u0e08\\u0e01\\u0e47\\u0e08\\u0e30\\u0e41\\u0e16\\u0e25\\u0e07\\u0e02\\u0e48\\u0e32\\u0e27\\u0e27\\u0e48\\u0e32\\u0e44\\u0e21\\u0e48\\u0e21\\u0e35\\u0e44\\u0e21\\u0e48\\u0e40\\u0e04\\u0e22\\u0e21\\u0e35\",\n          \"\\u0e1b\\u0e48\\u0e32\\u0e19\\u0e19\\u0e35\\u0e49\\u0e19\\u0e32\\u0e07\\u0e41\\u0e1a\\u0e21 \\u0e40\\u0e1b\\u0e47\\u0e07\\u0e44\\u0e07\\u0e1a\\u0e49\\u0e32\\u0e07\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-c2882bd9-b9f8-4ecc-8ce0-e5881d23706e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>comments</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>pos</td>\n",
              "      <td>ถ้าครั้งนี้มันจะเป็นบทเรียน ก็จะดีมากถ้านายห้า...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>neu</td>\n",
              "      <td>พี่หนุ่มคือที่สุด</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neu</td>\n",
              "      <td>แก๊ป แสตมป์ บอส ลำใย และอีกหลายๆ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>pos</td>\n",
              "      <td>ใหทองคำเคยผ่านมรสุมมาแล้วแต่ก็แกร็งและยังยืนอย...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>neg</td>\n",
              "      <td>นายฮ่างทำถูกแล้วละทะเลาะกับเด็กไปตัวเองก็มีแต่...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c2882bd9-b9f8-4ecc-8ce0-e5881d23706e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c2882bd9-b9f8-4ecc-8ce0-e5881d23706e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c2882bd9-b9f8-4ecc-8ce0-e5881d23706e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e6e4836d-72bf-43da-b17f-7b8fdfeacdbe\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e6e4836d-72bf-43da-b17f-7b8fdfeacdbe')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e6e4836d-72bf-43da-b17f-7b8fdfeacdbe button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "  category                                           comments\n",
              "0      pos  ถ้าครั้งนี้มันจะเป็นบทเรียน ก็จะดีมากถ้านายห้า...\n",
              "1      neu                                  พี่หนุ่มคือที่สุด\n",
              "2      neu                   แก๊ป แสตมป์ บอส ลำใย และอีกหลายๆ\n",
              "3      pos  ใหทองคำเคยผ่านมรสุมมาแล้วแต่ก็แกร็งและยังยืนอย...\n",
              "4      neg  นายฮ่างทำถูกแล้วละทะเลาะกับเด็กไปตัวเองก็มีแต่..."
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.DataFrame({ \"category\": labels, \"comments\": comments })\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ixLLajQ50YCI"
      },
      "outputs": [],
      "source": [
        "df = df.drop_duplicates()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "gbEL3Buf0aRr",
        "outputId": "3bffe7e9-50a5-4a7d-9b30-e8a443905214"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"neu_df\",\n  \"rows\": 18390,\n  \"fields\": [\n    {\n      \"column\": \"category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"neu\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"comments\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 18390,\n        \"samples\": [\n          \"\\u0e2b\\u0e19\\u0e49\\u0e32\\u0e21\\u0e35\\u0e19\\u0e21\\u0e32\\u0e01\\u0e22\\u0e31\\u0e07\\u0e01\\u0e25\\u0e49\\u0e32\\u0e21\\u0e32\\u0e2d\\u0e2d\\u0e01\\u0e42\\u0e2b\\u0e19\\u0e01\\u0e23\\u0e30\\u0e41\\u0e2a \\u0e44\\u0e21\\u0e48\\u0e2d\\u0e32\\u0e22\\u0e19\\u0e31\\u0e48\\u0e07\\u0e22\\u0e34\\u0e49\\u0e21 \\u0e40\\u0e09\\u0e22\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "neu_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-284084cc-a605-4913-bafc-c25af68aa127\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>comments</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>neu</td>\n",
              "      <td>พี่หนุ่มคือที่สุด</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neu</td>\n",
              "      <td>แก๊ป แสตมป์ บอส ลำใย และอีกหลายๆ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>neu</td>\n",
              "      <td>คนต้นเรื่องคือผชทั้งนั้นเลยนะ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>neu</td>\n",
              "      <td>เกิดเรื่องตกลงเจรจากันสิงหาคม หลังปีใหม่ยังสนิ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>neu</td>\n",
              "      <td>น้ำตากูไหลเลย</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-284084cc-a605-4913-bafc-c25af68aa127')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-284084cc-a605-4913-bafc-c25af68aa127 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-284084cc-a605-4913-bafc-c25af68aa127');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-988a0b04-a92a-4f93-a1c0-79ef943f158e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-988a0b04-a92a-4f93-a1c0-79ef943f158e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-988a0b04-a92a-4f93-a1c0-79ef943f158e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   category                                           comments\n",
              "1       neu                                  พี่หนุ่มคือที่สุด\n",
              "2       neu                   แก๊ป แสตมป์ บอส ลำใย และอีกหลายๆ\n",
              "20      neu                      คนต้นเรื่องคือผชทั้งนั้นเลยนะ\n",
              "21      neu  เกิดเรื่องตกลงเจรจากันสิงหาคม หลังปีใหม่ยังสนิ...\n",
              "23      neu                                      น้ำตากูไหลเลย"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "neu_df = df[df.category == \"neu\"]\n",
        "neu_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ZPK1kxPSZrY4",
        "outputId": "e3528467-6b87-4b8d-c005-993677bc679f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"bly_df\",\n  \"rows\": 1300,\n  \"fields\": [\n    {\n      \"column\": \"category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"bly\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"comments\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1300,\n        \"samples\": [\n          \"\\u0e14\\u0e2d\\u0e01\\u0e40\\u0e15\\u0e2d\\u0e23\\u0e4c\\u0e14\\u0e2d\\u0e01\\u0e41\\u0e14 \\u0e42\\u0e0a\\u0e27\\u0e4c\\u0e2a\\u0e31\\u0e19\\u0e14\\u0e32\\u0e19 \\u0e42\\u0e0a\\u0e27\\u0e4c\\u0e42\\u0e07\\u0e48 \\u0e40\\u0e23\\u0e37\\u0e48\\u0e2d\\u0e07\\u0e19\\u0e35\\u0e49\\u0e2a\\u0e2d\\u0e19\\u0e43\\u0e2b\\u0e49\\u0e23\\u0e39\\u0e49\\u0e27\\u0e48\\u0e32\\u0e04\\u0e19\\u0e08\\u0e1a\\u0e14\\u0e2d\\u0e01\\u0e40\\u0e15\\u0e2d\\u0e23\\u0e4c\\u0e44\\u0e21\\u0e48\\u0e44\\u0e14\\u0e49\\u0e09\\u0e25\\u0e32\\u0e14\\u0e17\\u0e38\\u0e01\\u0e04\\u0e19\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "bly_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-29f885ba-bf07-494d-bd4f-0b6d3510a180\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>comments</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>30802</th>\n",
              "      <td>bly</td>\n",
              "      <td>นายจ้างกล้าเปิดหน้าเนาะ มั่นหน้าว่าตัวเองถูก แ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62992</th>\n",
              "      <td>bly</td>\n",
              "      <td>หน้าร้อนหน้าหนาวหน้าด้าน</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59855</th>\n",
              "      <td>bly</td>\n",
              "      <td>เลวโดยสันดานจิงๆเห็นตั้งแต่เรื่องหวยมาแล้ว</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59613</th>\n",
              "      <td>bly</td>\n",
              "      <td>เสียงชู้เหมือนกระเทยมาก</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32681</th>\n",
              "      <td>bly</td>\n",
              "      <td>เปลี่ยนจากชื่อต่ายเป็นตายดีกว่าคับ นายจ้างเดรั...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-29f885ba-bf07-494d-bd4f-0b6d3510a180')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-29f885ba-bf07-494d-bd4f-0b6d3510a180 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-29f885ba-bf07-494d-bd4f-0b6d3510a180');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-20ffefdf-d336-4b49-987d-82fe5f6e93cb\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-20ffefdf-d336-4b49-987d-82fe5f6e93cb')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-20ffefdf-d336-4b49-987d-82fe5f6e93cb button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "      category                                           comments\n",
              "30802      bly  นายจ้างกล้าเปิดหน้าเนาะ มั่นหน้าว่าตัวเองถูก แ...\n",
              "62992      bly                           หน้าร้อนหน้าหนาวหน้าด้าน\n",
              "59855      bly         เลวโดยสันดานจิงๆเห็นตั้งแต่เรื่องหวยมาแล้ว\n",
              "59613      bly                            เสียงชู้เหมือนกระเทยมาก\n",
              "32681      bly  เปลี่ยนจากชื่อต่ายเป็นตายดีกว่าคับ นายจ้างเดรั..."
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bly_df = df[df.category == \"bly\"].sample(1300)\n",
        "bly_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "SPDLE6OfZt5f",
        "outputId": "0b0db9ad-c81f-4f0a-a9c1-ef826b35ad8d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"hig_df\",\n  \"rows\": 1300,\n  \"fields\": [\n    {\n      \"column\": \"category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"hig\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"comments\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1300,\n        \"samples\": [\n          \"\\u0e44\\u0e2d\\u0e49\\u0e19\\u0e35\\u0e49\\u0e41\\u0e21\\u0e48\\u0e07\\u0e42\\u0e17\\u0e29\\u0e25\\u0e33\\u0e43\\u0e19\\u0e01\\u0e31\\u0e1a\\u0e42\\u0e21\\u0e2d\\u0e22\\u0e48\\u0e32\\u0e07\\u0e40\\u0e14\\u0e35\\u0e22\\u0e27\\u0e40\\u0e25\\u0e22\\u0e27\\u0e48\\u0e30\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "hig_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-7d4829e6-ba58-4634-ae8f-dca53c0f4a16\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>comments</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>19819</th>\n",
              "      <td>hig</td>\n",
              "      <td>ไอ้บอสเอ๊ยตอบคำถามแบบไม่แมนเลยแบบนี้มึงจะเป็นผ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24626</th>\n",
              "      <td>hig</td>\n",
              "      <td>เหตุนี้ก็เป็นอุทาหรณ์ที่ดี เรื่องรถยนต์ผิดแน่ๆ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31346</th>\n",
              "      <td>hig</td>\n",
              "      <td>คนจังไรมักแก้ตัว ไม่แก้ไขสันดานเฮี้ยจริงๆ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42470</th>\n",
              "      <td>hig</td>\n",
              "      <td>เห้อ ดร สงสัยใช้สมองเยอะจนแยกแยะไม่ออก</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61009</th>\n",
              "      <td>hig</td>\n",
              "      <td>ใอ้ชาแม่งหัวก็ล้านก็กลมนะ แต่แม่งเหลี่ยมเยอะฉิ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7d4829e6-ba58-4634-ae8f-dca53c0f4a16')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7d4829e6-ba58-4634-ae8f-dca53c0f4a16 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7d4829e6-ba58-4634-ae8f-dca53c0f4a16');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fe5d6c1b-a651-4b9e-8223-af5f09245a8f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fe5d6c1b-a651-4b9e-8223-af5f09245a8f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fe5d6c1b-a651-4b9e-8223-af5f09245a8f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "      category                                           comments\n",
              "19819      hig  ไอ้บอสเอ๊ยตอบคำถามแบบไม่แมนเลยแบบนี้มึงจะเป็นผ...\n",
              "24626      hig  เหตุนี้ก็เป็นอุทาหรณ์ที่ดี เรื่องรถยนต์ผิดแน่ๆ...\n",
              "31346      hig          คนจังไรมักแก้ตัว ไม่แก้ไขสันดานเฮี้ยจริงๆ\n",
              "42470      hig             เห้อ ดร สงสัยใช้สมองเยอะจนแยกแยะไม่ออก\n",
              "61009      hig  ใอ้ชาแม่งหัวก็ล้านก็กลมนะ แต่แม่งเหลี่ยมเยอะฉิ..."
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hig_df = df[df.category == \"hig\"].sample(1300)\n",
        "hig_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "5KPa6awU0fd5",
        "outputId": "4c8300ee-fa62-4c92-9847-0cae1271005a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"pos_df\",\n  \"rows\": 1300,\n  \"fields\": [\n    {\n      \"column\": \"category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"pos\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"comments\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1300,\n        \"samples\": [\n          \"\\u0e2d\\u0e22\\u0e32\\u0e01\\u0e44\\u0e14\\u0e49\\u0e1c\\u0e49\\u0e32\\u0e2b\\u0e48\\u0e21 \\u0e07\\u0e31\\u0e1a\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "pos_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-ab0eb932-208b-4057-8ead-5f493470f673\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>comments</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12702</th>\n",
              "      <td>pos</td>\n",
              "      <td>ได้สองล้านเป็นฉันดีใจมาก ได้เงิน ได้ทิ้งคนเจ้า...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6906</th>\n",
              "      <td>pos</td>\n",
              "      <td>ถ้าอีกทางไม่ใช่คนดัง คุณจะยังให้บอสออกมาพูดให้...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6295</th>\n",
              "      <td>pos</td>\n",
              "      <td>คุณโมก็น่ารักใช่เล่นเลยนะครับ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14538</th>\n",
              "      <td>pos</td>\n",
              "      <td>ดูไปก่อนดีกว่าเดินทางสยกลาง</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41263</th>\n",
              "      <td>pos</td>\n",
              "      <td>เนี่ยทำดีได้ดีมีที่ไหนทำชั่วได้ดีมีถมไปแม่อ้อย...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ab0eb932-208b-4057-8ead-5f493470f673')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ab0eb932-208b-4057-8ead-5f493470f673 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ab0eb932-208b-4057-8ead-5f493470f673');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-857de0b1-10e7-4a68-9b10-a5b32ad980c3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-857de0b1-10e7-4a68-9b10-a5b32ad980c3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-857de0b1-10e7-4a68-9b10-a5b32ad980c3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "      category                                           comments\n",
              "12702      pos  ได้สองล้านเป็นฉันดีใจมาก ได้เงิน ได้ทิ้งคนเจ้า...\n",
              "6906       pos  ถ้าอีกทางไม่ใช่คนดัง คุณจะยังให้บอสออกมาพูดให้...\n",
              "6295       pos                      คุณโมก็น่ารักใช่เล่นเลยนะครับ\n",
              "14538      pos                        ดูไปก่อนดีกว่าเดินทางสยกลาง\n",
              "41263      pos  เนี่ยทำดีได้ดีมีที่ไหนทำชั่วได้ดีมีถมไปแม่อ้อย..."
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pos_df = df[df.category == \"pos\"].sample(1300)\n",
        "pos_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "OYlqQSPV0o7n",
        "outputId": "899cc9ac-5402-4e31-9e3b-408a38a68f58"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"neg_df\",\n  \"rows\": 1300,\n  \"fields\": [\n    {\n      \"column\": \"category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"neg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"comments\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1300,\n        \"samples\": [\n          \"\\u0e40\\u0e08\\u0e49\\u0e32\\u0e02\\u0e2d\\u0e07\\u0e1a\\u0e49\\u0e32\\u0e19\\u0e19\\u0e31\\u0e49\\u0e19\\u0e25\\u0e30 \\u0e21\\u0e31\\u0e19\\u0e04\\u0e07\\u0e01\\u0e30\\u0e27\\u0e48\\u0e32\\u0e43\\u0e2b\\u0e49\\u0e44\\u0e1f\\u0e44\\u0e2b\\u0e21\\u0e49\\u0e17\\u0e31\\u0e49\\u0e07\\u0e2b\\u0e25\\u0e31\\u0e07\\u0e40\\u0e25\\u0e22\\u0e41\\u0e2b\\u0e25\\u0e30 \\u0e41\\u0e15\\u0e48\\u0e40\\u0e02\\u0e32\\u0e14\\u0e31\\u0e19\\u0e14\\u0e31\\u0e1a\\u0e44\\u0e1f\\u0e44\\u0e27\\u0e44\\u0e1b \\u0e21\\u0e31\\u0e19\\u0e23\\u0e31\\u0e1a\\u0e2a\\u0e32\\u0e23\\u0e30\\u0e20\\u0e32\\u0e1e\\u0e41\\u0e25\\u0e49\\u0e27\\u0e25\\u0e30 \\u0e1a\\u0e31\\u0e0d\\u0e0a\\u0e35\\u0e21\\u0e49\\u0e32 \\u0e23\\u0e48\\u0e27\\u0e21\\u0e01\\u0e31\\u0e19\\u0e27\\u0e32\\u0e07\\u0e41\\u0e1c\\u0e19 \\u0e08\\u0e38\\u0e14\\u0e44\\u0e1f\\u0e40\\u0e1c\\u0e32\\u0e40\\u0e2d\\u0e07 \\u0e44\\u0e21\\u0e48\\u0e23\\u0e39\\u0e49\\u0e40\\u0e1e\\u0e23\\u0e32\\u0e30 \\u0e2d\\u0e30\\u0e44\\u0e23\\u0e41\\u0e15\\u0e48\\u0e40\\u0e01\\u0e35\\u0e48\\u0e22\\u0e27\\u0e01\\u0e31\\u0e1a\\u0e40\\u0e07\\u0e34\\u0e19\\u0e43\\u0e19\\u0e2a\\u0e48\\u0e27\\u0e19\\u0e19\\u0e35\\u0e49\\u0e40\\u0e40\\u0e19\\u0e48\\u0e19\\u0e2d\\u0e19 \\u0e2d\\u0e32\\u0e08\\u0e08\\u0e30\\u0e40\\u0e2d\\u0e32\\u0e40\\u0e07\\u0e34\\u0e19\\u0e40\\u0e08\\u0e49\\u0e32\\u0e19\\u0e32\\u0e22\\u0e44\\u0e1b\\u0e43\\u0e0a\\u0e49\\u0e41\\u0e25\\u0e49\\u0e27 \\u0e2b\\u0e23\\u0e37\\u0e2d \\u0e42\\u0e25\\u0e20\\u0e2d\\u0e22\\u0e32\\u0e01\\u0e08\\u0e30\\u0e44\\u0e14\\u0e49\\u0e40\\u0e07\\u0e34\\u0e19\\u0e2a\\u0e48\\u0e27\\u0e19\\u0e19\\u0e35\\u0e49 \\u0e40\\u0e25\\u0e22\\u0e27\\u0e32\\u0e07\\u0e41\\u0e1c\\u0e19 \\u0e41\\u0e25\\u0e49\\u0e27\\u0e40\\u0e01\\u0e34\\u0e14\\u0e40\\u0e2b\\u0e15\\u0e38\\u0e01\\u0e32\\u0e23\\u0e19\\u0e35\\u0e49\\u0e02\\u0e36\\u0e49\\u0e19\\u0e21\\u0e32 \\u0e0a\\u0e31\\u0e14\\u0e40\\u0e08\\u0e19\\u0e04\\u0e23\\u0e31\\u0e1a \\u0e21\\u0e31\\u0e19\\u0e40\\u0e1b\\u0e47\\u0e19\\u0e40\\u0e07\\u0e34\\u0e19\\u0e44\\u0e21\\u0e48\\u0e02\\u0e32\\u0e27\\u0e2a\\u0e30\\u0e2d\\u0e32\\u0e14\\u0e41\\u0e19\\u0e48\\u0e19\\u0e2d\\u0e19 \\u0e40\\u0e27\\u0e47\\u0e1b\\u0e1e\\u0e19\\u0e31\\u0e19\\u0e23\\u0e36\\u0e1b\\u0e48\\u0e32\\u0e27\\u0e19\\u0e4a\\u0e32 \\u0e2a\\u0e37\\u0e1a\\u0e15\\u0e48\\u0e2d\\u0e40\\u0e25\\u0e22\\u0e04\\u0e23\\u0e31\\u0e1a \\u0e07\\u0e32\\u0e19\\u0e19\\u0e35\\u0e49\\u0e21\\u0e35\\u0e04\\u0e19\\u0e15\\u0e34\\u0e14\\u0e04\\u0e38\\u0e01\\u0e41\\u0e19\\u0e48\\u0e19\\u0e2d\\u0e19\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "neg_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-67c40bbd-88f1-4655-a40f-a70d87ff97fc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>comments</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>46221</th>\n",
              "      <td>neg</td>\n",
              "      <td>แสดงว่าอีพวกนี้อยากจะจัดผัวเขาพอเมียเขาโทรมาตา...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28713</th>\n",
              "      <td>neg</td>\n",
              "      <td>ฉันล่ะเกลียดแม่ที่ชอบไปเบิกเงินล่วงหน้าที่ลูกเ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8126</th>\n",
              "      <td>neg</td>\n",
              "      <td>สรุปก็คือจะเอาทั้งเงินและต้องให้เสียชื่อเสียงด...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6381</th>\n",
              "      <td>neg</td>\n",
              "      <td>เอาซะเรื่องแตงโมตกเรือเงียบไปเลยคะ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7945</th>\n",
              "      <td>neg</td>\n",
              "      <td>ผู้ชายแบบนี้ควรเลิกตั้งแต่ตกงานเพราะแอบถ่ายแล้...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-67c40bbd-88f1-4655-a40f-a70d87ff97fc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-67c40bbd-88f1-4655-a40f-a70d87ff97fc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-67c40bbd-88f1-4655-a40f-a70d87ff97fc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6948e0a3-5583-4632-87df-c6317aee6583\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6948e0a3-5583-4632-87df-c6317aee6583')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6948e0a3-5583-4632-87df-c6317aee6583 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "      category                                           comments\n",
              "46221      neg  แสดงว่าอีพวกนี้อยากจะจัดผัวเขาพอเมียเขาโทรมาตา...\n",
              "28713      neg  ฉันล่ะเกลียดแม่ที่ชอบไปเบิกเงินล่วงหน้าที่ลูกเ...\n",
              "8126       neg  สรุปก็คือจะเอาทั้งเงินและต้องให้เสียชื่อเสียงด...\n",
              "6381       neg                 เอาซะเรื่องแตงโมตกเรือเงียบไปเลยคะ\n",
              "7945       neg  ผู้ชายแบบนี้ควรเลิกตั้งแต่ตกงานเพราะแอบถ่ายแล้..."
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "neg_df = df[df.category == \"neg\"].sample(1300)\n",
        "neg_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "i9iMD4Ub0wOM",
        "outputId": "91e7efb2-30e4-4b60-b066-a16576606874"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"sentiment_df\",\n  \"rows\": 5200,\n  \"fields\": [\n    {\n      \"column\": \"category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"neg\",\n          \"bly\",\n          \"pos\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"comments\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5200,\n        \"samples\": [\n          \"\\u0e1c\\u0e21\\u0e44\\u0e21\\u0e48\\u0e40\\u0e0a\\u0e37\\u0e48\\u0e2d\\u0e15\\u0e31\\u0e49\\u0e07\\u0e41\\u0e15\\u0e48\\u0e2d\\u0e2d\\u0e01\\u0e40\\u0e17\\u0e1b\\u0e41\\u0e23\\u0e01\\u0e46\\u0e41\\u0e25\\u0e49\\u0e27 \\u0e1a\\u0e2d\\u0e01\\u0e25\\u0e49\\u0e32\\u0e07\\u0e01\\u0e49\\u0e19\\u0e43\\u0e2b\\u0e49\\u0e01\\u0e31\\u0e19\\u0e14\\u0e49\\u0e27\\u0e22 \\u0e2e\\u0e32\\u0e40\\u0e25\\u0e22\",\n          \"\\u0e01\\u0e39\\u0e42\\u0e04\\u0e15\\u0e23\\u0e08\\u0e30\\u0e02\\u0e33\\u0e40\\u0e25\\u0e22\",\n          \"\\u0e40\\u0e21\\u0e37\\u0e48\\u0e2d\\u0e27\\u0e32\\u0e19\\u0e44\\u0e2d\\u0e1a\\u0e2d\\u0e2a\\u0e01\\u0e47\\u0e27\\u0e48\\u0e32\\u0e44\\u0e21\\u0e48\\u0e44\\u0e14\\u0e49\\u0e15\\u0e35\\u0e01\\u0e31\\u0e19\\u0e19\\u0e30\\u0e21\\u0e36\\u0e07\\u0e1e\\u0e39\\u0e14\\u0e40\\u0e2d\\u0e07\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "sentiment_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-bb0baf7b-d302-47cb-a0c6-45082ead774e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>comments</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12702</th>\n",
              "      <td>pos</td>\n",
              "      <td>ได้สองล้านเป็นฉันดีใจมาก ได้เงิน ได้ทิ้งคนเจ้า...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6906</th>\n",
              "      <td>pos</td>\n",
              "      <td>ถ้าอีกทางไม่ใช่คนดัง คุณจะยังให้บอสออกมาพูดให้...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6295</th>\n",
              "      <td>pos</td>\n",
              "      <td>คุณโมก็น่ารักใช่เล่นเลยนะครับ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14538</th>\n",
              "      <td>pos</td>\n",
              "      <td>ดูไปก่อนดีกว่าเดินทางสยกลาง</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41263</th>\n",
              "      <td>pos</td>\n",
              "      <td>เนี่ยทำดีได้ดีมีที่ไหนทำชั่วได้ดีมีถมไปแม่อ้อย...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45103</th>\n",
              "      <td>pos</td>\n",
              "      <td>สาวไม่มีสมองมีดีเเค่ปาก</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50946</th>\n",
              "      <td>pos</td>\n",
              "      <td>อิเด็ก ก็ปากแซ่บไม่เบา</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10424</th>\n",
              "      <td>pos</td>\n",
              "      <td>หลักฐานมีน้องไม่ต้องกลัวตรวจสอบได้ น้องเงียบเก...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55704</th>\n",
              "      <td>pos</td>\n",
              "      <td>เทปนี้ ผมอย่างชอบ ฮาทั้งเทป</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42527</th>\n",
              "      <td>pos</td>\n",
              "      <td>ลูกๆคือดีและน่ารักมาก พร้อมจะเคียงข้างแม่ เพื่...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bb0baf7b-d302-47cb-a0c6-45082ead774e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bb0baf7b-d302-47cb-a0c6-45082ead774e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bb0baf7b-d302-47cb-a0c6-45082ead774e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-83a933f0-62fe-4c58-ae0e-edf912cf2df7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-83a933f0-62fe-4c58-ae0e-edf912cf2df7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-83a933f0-62fe-4c58-ae0e-edf912cf2df7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "      category                                           comments\n",
              "12702      pos  ได้สองล้านเป็นฉันดีใจมาก ได้เงิน ได้ทิ้งคนเจ้า...\n",
              "6906       pos  ถ้าอีกทางไม่ใช่คนดัง คุณจะยังให้บอสออกมาพูดให้...\n",
              "6295       pos                      คุณโมก็น่ารักใช่เล่นเลยนะครับ\n",
              "14538      pos                        ดูไปก่อนดีกว่าเดินทางสยกลาง\n",
              "41263      pos  เนี่ยทำดีได้ดีมีที่ไหนทำชั่วได้ดีมีถมไปแม่อ้อย...\n",
              "...        ...                                                ...\n",
              "45103      pos                            สาวไม่มีสมองมีดีเเค่ปาก\n",
              "50946      pos                             อิเด็ก ก็ปากแซ่บไม่เบา\n",
              "10424      pos  หลักฐานมีน้องไม่ต้องกลัวตรวจสอบได้ น้องเงียบเก...\n",
              "55704      pos                        เทปนี้ ผมอย่างชอบ ฮาทั้งเทป\n",
              "42527      pos  ลูกๆคือดีและน่ารักมาก พร้อมจะเคียงข้างแม่ เพื่...\n",
              "\n",
              "[1000 rows x 2 columns]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sentiment_df = pd.concat([pos_df,neg_df,hig_df,bly_df])\n",
        "sentiment_df.head(1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNBhmEZj01HO",
        "outputId": "0626484a-858e-4a77-c49a-b34fd7f091db"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(5200,)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "comments = sentiment_df.comments.values\n",
        "comments.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "sufRobjI04TG",
        "outputId": "2de6ba29-a49a-47c4-c84d-c763ccbed5cb"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ได้สองล้านเป็นฉันดีใจมาก ได้เงิน ได้ทิ้งคนเจ้าชู้ ได้ชีวิตใหม่ ฉันจะอยู่เงียบเงียบสวยสวย หาแฟนใหม่'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "comments[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TcCqHnpa06ny",
        "outputId": "ed80dd7d-f22c-4795-801f-b136e47c9c4b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(5200,)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "category = sentiment_df.category.values\n",
        "category.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwBk607Y1BCT"
      },
      "outputs": [],
      "source": [
        "def cleaning(sentences):\n",
        "  words = []\n",
        "  temp = []\n",
        "  for s in sentences:\n",
        "    clean = re.sub(r'[^ก-๙]', \"\", s)\n",
        "    w = word_tokenize(clean)\n",
        "    temp.append([i.lower() for i in w])\n",
        "    words.append(' '.join(w).lower())\n",
        "\n",
        "  return words, temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvLdLo4Y1Dp-",
        "outputId": "591e0470-9fef-492d-e75e-8234416307bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5200\n",
            "['ได้ สอง ล้าน เป็น ฉัน ดีใจ มาก ได้ เงินได้ ทิ้ง คนเจ้าชู้ ได้ ชีวิต ใหม่ ฉัน จะ อยู่ เงียบ เงียบ สวย สวย หา แฟน ใหม่', 'ถ้า อีก ทาง ไม่ ใช่ คนดัง คุณ จะ ยัง ให้ บอส ออกมา พูด ให้ ใคร ฟัง อีก มั้ย ใน เมื่อ เวลา รัก กัน มัน เป็นเรื่อง ของ คน คน', 'คุณ โม ก็ น่ารัก ใช่ เล่น เลย นะ ครับ', 'ดูไปก่อน ดีกว่า เดินทาง สย กลาง', 'เนี่ย ทำดี ได้ดี มี ที่ไหน ทำชั่ว ได้ดี มี ถมไป แม่ อ้อย สู้ ๆๆ']\n"
          ]
        }
      ],
      "source": [
        "cleaned_words, temp = cleaning(comments)\n",
        "print(len(cleaned_words))\n",
        "print(cleaned_words[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5OPtEa-N1FnR"
      },
      "outputs": [],
      "source": [
        "def create_tokenizer(words, filters = ''):\n",
        "    token = Tokenizer(filters=filters)\n",
        "    token.fit_on_texts(words)\n",
        "    return token"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVPvdWqX1KX5"
      },
      "source": [
        "train_word_tokenizer = create_tokenizer(cleaned_words)\n",
        "vocab_size = len(train_word_tokenizer.word_index) + 1\n",
        "train_word_tokenizer.word_index\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhlsisJQQxKQ",
        "outputId": "9c8b6231-3723-47cd-c61d-281093cd1ab3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'ไม่': 1,\n",
              " 'ก็': 2,\n",
              " 'คน': 3,\n",
              " 'เลย': 4,\n",
              " 'ไป': 5,\n",
              " 'ที่': 6,\n",
              " 'จะ': 7,\n",
              " 'มี': 8,\n",
              " 'แล้ว': 9,\n",
              " 'มา': 10,\n",
              " 'เป็น': 11,\n",
              " 'เขา': 12,\n",
              " 'ได้': 13,\n",
              " 'มัน': 14,\n",
              " 'ว่า': 15,\n",
              " 'ให้': 16,\n",
              " 'แต่': 17,\n",
              " 'ๆ': 18,\n",
              " 'นะ': 19,\n",
              " 'นี้': 20,\n",
              " 'มาก': 21,\n",
              " 'พูด': 22,\n",
              " 'กับ': 23,\n",
              " 'ถ้า': 24,\n",
              " 'มึง': 25,\n",
              " 'กัน': 26,\n",
              " 'เอา': 27,\n",
              " 'ครับ': 28,\n",
              " 'โม': 29,\n",
              " 'อะไร': 30,\n",
              " 'เรื่อง': 31,\n",
              " 'ทำ': 32,\n",
              " 'ดู': 33,\n",
              " 'น้อง': 34,\n",
              " 'ต้อง': 35,\n",
              " 'คุณ': 36,\n",
              " 'คือ': 37,\n",
              " 'ค่ะ': 38,\n",
              " 'แบบนี้': 39,\n",
              " 'โดน': 40,\n",
              " 'ใคร': 41,\n",
              " 'พี่': 42,\n",
              " 'เค้า': 43,\n",
              " 'และ': 44,\n",
              " 'อีก': 45,\n",
              " 'ใน': 46,\n",
              " 'ยัง': 47,\n",
              " 'กู': 48,\n",
              " 'ตัวเอง': 49,\n",
              " 'ดี': 50,\n",
              " 'ผม': 51,\n",
              " 'ของ': 52,\n",
              " 'บอส': 53,\n",
              " 'อยู่': 54,\n",
              " 'รู้': 55,\n",
              " 'เพราะ': 56,\n",
              " 'ผู้ชาย': 57,\n",
              " 'เรา': 58,\n",
              " 'เหมือน': 59,\n",
              " 'เมีย': 60,\n",
              " 'ฟัง': 61,\n",
              " 'ผิด': 62,\n",
              " 'แม่': 63,\n",
              " 'เงิน': 64,\n",
              " 'ลูก': 65,\n",
              " 'จริงๆ': 66,\n",
              " 'พวก': 67,\n",
              " 'นายจ้าง': 68,\n",
              " 'นี่': 69,\n",
              " 'คิด': 70,\n",
              " 'จบ': 71,\n",
              " 'ทำไม': 72,\n",
              " 'แบบ': 73,\n",
              " 'อยาก': 74,\n",
              " 'เลว': 75,\n",
              " 'บอก': 76,\n",
              " 'ผู้หญิง': 77,\n",
              " 'ด้วย': 78,\n",
              " 'ผัว': 79,\n",
              " 'จาก': 80,\n",
              " 'ทั้ง': 81,\n",
              " 'แค่': 82,\n",
              " 'คลิป': 83,\n",
              " 'กว่า': 84,\n",
              " 'อี': 85,\n",
              " 'ใช่': 86,\n",
              " 'อย่า': 87,\n",
              " 'ตี': 88,\n",
              " 'หรือ': 89,\n",
              " 'รัก': 90,\n",
              " 'เชื่อ': 91,\n",
              " 'ละ': 92,\n",
              " 'พอ': 93,\n",
              " 'แฟน': 94,\n",
              " 'หนุ่ม': 95,\n",
              " 'สงสาร': 96,\n",
              " 'จริง': 97,\n",
              " 'ถึง': 98,\n",
              " 'นั้น': 99,\n",
              " 'การ': 100,\n",
              " 'อย่าง': 101,\n",
              " 'สันดาน': 102,\n",
              " 'ควร': 103,\n",
              " 'หมด': 104,\n",
              " 'เด็ก': 105,\n",
              " 'ขนาด': 106,\n",
              " 'ล้าน': 107,\n",
              " 'ออก': 108,\n",
              " 'ก่อน': 109,\n",
              " 'ชอบ': 110,\n",
              " 'ถูก': 111,\n",
              " 'หน้า': 112,\n",
              " 'คนอื่น': 113,\n",
              " 'หมา': 114,\n",
              " 'เจอ': 115,\n",
              " 'เคย': 116,\n",
              " 'ตัว': 117,\n",
              " 'เห็น': 118,\n",
              " 'สุด': 119,\n",
              " 'ยังไง': 120,\n",
              " 'เข้าใจ': 121,\n",
              " 'ไอ้': 122,\n",
              " 'คง': 123,\n",
              " 'ง': 124,\n",
              " 'งง': 125,\n",
              " 'ลำไย': 126,\n",
              " 'รุม': 127,\n",
              " 'เยอะ': 128,\n",
              " 'ไหน': 129,\n",
              " 'ฟ้อง': 130,\n",
              " 'เอง': 131,\n",
              " 'บอ': 132,\n",
              " 'หรอก': 133,\n",
              " 'โคตร': 134,\n",
              " 'ตอแหล': 135,\n",
              " 'ออกมา': 136,\n",
              " 'ไว้': 137,\n",
              " 'ส่วน': 138,\n",
              " 'ม': 139,\n",
              " 'ถ่าย': 140,\n",
              " 'คะ': 141,\n",
              " 'หรอ': 142,\n",
              " 'ฝ่าย': 143,\n",
              " 'นะคะ': 144,\n",
              " 'ถาม': 145,\n",
              " 'เรียก': 146,\n",
              " 'โกหก': 147,\n",
              " 'พ่อ': 148,\n",
              " 'ขอ': 149,\n",
              " 'ใจ': 150,\n",
              " 'เพื่อ': 151,\n",
              " 'ครู': 152,\n",
              " 'ไง': 153,\n",
              " 'ช่วย': 154,\n",
              " 'รายการ': 155,\n",
              " 'จน': 156,\n",
              " 'ความ': 157,\n",
              " 'อ่ะ': 158,\n",
              " 'ไหม': 159,\n",
              " 'คำ': 160,\n",
              " 'บ้าง': 161,\n",
              " 'สู้': 162,\n",
              " 'หลอก': 163,\n",
              " 'นอกใจ': 164,\n",
              " 'บ้าน': 165,\n",
              " 'ลำ': 166,\n",
              " 'เลิก': 167,\n",
              " 'ชีวิต': 168,\n",
              " 'เก่ง': 169,\n",
              " 'แบ': 170,\n",
              " 'ยิ่ง': 171,\n",
              " 'ตอน': 172,\n",
              " 'น่าจะ': 173,\n",
              " 'เกิด': 174,\n",
              " 'ใช้': 175,\n",
              " 'หญิง': 176,\n",
              " 'ใย': 177,\n",
              " 'ทำร้าย': 178,\n",
              " 'อะ': 179,\n",
              " 'ทาง': 180,\n",
              " 'ทนาย': 181,\n",
              " 'จ่าย': 182,\n",
              " 'ทำให้': 183,\n",
              " 'กล้า': 184,\n",
              " 'ตบ': 185,\n",
              " 'ตาม': 186,\n",
              " 'แถ': 187,\n",
              " 'ครอบครัว': 188,\n",
              " 'อาจารย์': 189,\n",
              " 'นาง': 190,\n",
              " 'สังคม': 191,\n",
              " 'กก': 192,\n",
              " 'ด่า': 193,\n",
              " 'น่ะ': 194,\n",
              " 'ฝั่ง': 195,\n",
              " 'ทุก': 196,\n",
              " 'คบ': 197,\n",
              " 'น': 198,\n",
              " 'ผช': 199,\n",
              " 'ดร': 200,\n",
              " 'ล่ะ': 201,\n",
              " 'ปล่อย': 202,\n",
              " 'คุย': 203,\n",
              " 'เดียว': 204,\n",
              " 'หนัก': 205,\n",
              " 'แมน': 206,\n",
              " 'น่า': 207,\n",
              " 'ต่อ': 208,\n",
              " 'คับ': 209,\n",
              " 'หา': 210,\n",
              " 'ขำ': 211,\n",
              " 'ตำรวจ': 212,\n",
              " 'มั้ย': 213,\n",
              " 'กะ': 214,\n",
              " 'ค่าย': 215,\n",
              " 'รับ': 216,\n",
              " 'เพื่อน': 217,\n",
              " 'สิ': 218,\n",
              " 'สวย': 219,\n",
              " 'ยอม': 220,\n",
              " 'แฉ': 221,\n",
              " 'ปกป้อง': 222,\n",
              " 'เธอ': 223,\n",
              " 'ปาก': 224,\n",
              " 'กิน': 225,\n",
              " 'ขอให้': 226,\n",
              " 'ทุกคน': 227,\n",
              " 'เสีย': 228,\n",
              " 'ที่สุด': 229,\n",
              " 'โค': 230,\n",
              " 'ใหม่': 231,\n",
              " 'หน้าตา': 232,\n",
              " 'แหละ': 233,\n",
              " 'ตอบ': 234,\n",
              " 'วะ': 235,\n",
              " 'หลาย': 236,\n",
              " 'จัง': 237,\n",
              " 'สอง': 238,\n",
              " 'ไร': 239,\n",
              " 'ปุ้ย': 240,\n",
              " 'ปรีชา': 241,\n",
              " 'หน่อย': 242,\n",
              " 'ทำงาน': 243,\n",
              " 'ตาย': 244,\n",
              " 'จัด': 245,\n",
              " 'ผญ': 246,\n",
              " 'นึง': 247,\n",
              " 'ปี': 248,\n",
              " 'ก้อ': 249,\n",
              " 'เสือก': 250,\n",
              " 'มากกว่า': 251,\n",
              " 'สรุป': 252,\n",
              " 'ไม่ต้อง': 253,\n",
              " 'คำพูด': 254,\n",
              " 'กลัว': 255,\n",
              " 'ไอ': 256,\n",
              " 'ไทย': 257,\n",
              " 'โง่': 258,\n",
              " 'กลับ': 259,\n",
              " 'ที่จะ': 260,\n",
              " 'เหมือนกัน': 261,\n",
              " 'ประเด็น': 262,\n",
              " 'แน่': 263,\n",
              " 'อาจจะ': 264,\n",
              " 'ขอโทษ': 265,\n",
              " 'ตั้งแต่': 266,\n",
              " 'เถอะ': 267,\n",
              " 'แทน': 268,\n",
              " 'นายห้าง': 269,\n",
              " 'รต': 270,\n",
              " 'เวลา': 271,\n",
              " 'ร่า': 272,\n",
              " 'ปกติ': 273,\n",
              " 'ว่ะ': 274,\n",
              " 'ทุกอย่าง': 275,\n",
              " 'นาย': 276,\n",
              " 'ค่า': 277,\n",
              " 'เนี่ย': 278,\n",
              " 'ท่าน': 279,\n",
              " 'ส่ง': 280,\n",
              " 'เข้า': 281,\n",
              " 'ดีกว่า': 282,\n",
              " 'ๆๆ': 283,\n",
              " 'นั่ง': 284,\n",
              " 'แถม': 285,\n",
              " 'เหรอ': 286,\n",
              " 'บ้า': 287,\n",
              " 'สิ่ง': 288,\n",
              " 'ตลอด': 289,\n",
              " 'ตั้ง': 290,\n",
              " 'ซา': 291,\n",
              " 'กุ': 292,\n",
              " 'ก็ได้': 293,\n",
              " 'เหลี่ยม': 294,\n",
              " 'แน่นอน': 295,\n",
              " 'ลูกจ้าง': 296,\n",
              " 'ใส่': 297,\n",
              " 'รึ': 298,\n",
              " 'สาว': 299,\n",
              " 'หลักฐาน': 300,\n",
              " 'งาน': 301,\n",
              " 'รู้เรื่อง': 302,\n",
              " 'อยู่แล้ว': 303,\n",
              " 'ฉัน': 304,\n",
              " 'นิสัย': 305,\n",
              " 'น่าสงสาร': 306,\n",
              " 'หล่อ': 307,\n",
              " 'แก': 308,\n",
              " 'หัว': 309,\n",
              " 'นาน': 310,\n",
              " 'ซวย': 311,\n",
              " 'วันนี้': 312,\n",
              " 'ที': 313,\n",
              " 'สัก': 314,\n",
              " 'เก็บ': 315,\n",
              " 'เป็นเรื่อง': 316,\n",
              " 'น่ารัก': 317,\n",
              " 'ผัวเมีย': 318,\n",
              " 'ป่าว': 319,\n",
              " 'หาย': 320,\n",
              " 'เ': 321,\n",
              " 'แอบ': 322,\n",
              " 'หน้าด้าน': 323,\n",
              " 'ไห้': 324,\n",
              " 'สุดท้าย': 325,\n",
              " 'มารยาท': 326,\n",
              " 'รู้สึก': 327,\n",
              " 'คนเดียว': 328,\n",
              " 'ชาย': 329,\n",
              " 'ดีมาก': 330,\n",
              " 'น้อย': 331,\n",
              " 'หลุด': 332,\n",
              " 'ป่วย': 333,\n",
              " 'ขึ้น': 334,\n",
              " 'ก้': 335,\n",
              " 'แก้ว': 336,\n",
              " 'หมาย': 337,\n",
              " 'เรียน': 338,\n",
              " 'ความคิด': 339,\n",
              " 'หนู': 340,\n",
              " 'ตรง': 341,\n",
              " 'เสียใจ': 342,\n",
              " 'กำลังใจ': 343,\n",
              " 'มอง': 344,\n",
              " 'เจ็บ': 345,\n",
              " 'ดัง': 346,\n",
              " 'หยุด': 347,\n",
              " 'ป้า': 348,\n",
              " 'นักร้อง': 349,\n",
              " 'จับ': 350,\n",
              " 'ยาก': 351,\n",
              " 'ประสาท': 352,\n",
              " 'เลือก': 353,\n",
              " 'เสียหาย': 354,\n",
              " 'รถ': 355,\n",
              " 'สมควร': 356,\n",
              " 'มั่น': 357,\n",
              " 'เจ้านาย': 358,\n",
              " 'เลี้ยง': 359,\n",
              " 'เฮีย': 360,\n",
              " 'ชิบหาย': 361,\n",
              " 'สลด': 362,\n",
              " 'เข้าข้าง': 363,\n",
              " 'ได้เงิน': 364,\n",
              " 'ตลาด': 365,\n",
              " 'จ้าง': 366,\n",
              " 'ยอมรับ': 367,\n",
              " 'แย่': 368,\n",
              " 'ทำผิด': 369,\n",
              " 'ลง': 370,\n",
              " 'จ้า': 371,\n",
              " 'ส': 372,\n",
              " 'อา': 373,\n",
              " 'สำนึก': 374,\n",
              " 'สมอง': 375,\n",
              " 'เหี้ย': 376,\n",
              " 'เสื้อ': 377,\n",
              " 'แน่ๆ': 378,\n",
              " 'เกิน': 379,\n",
              " 'ห้าม': 380,\n",
              " 'เดี๋ยว': 381,\n",
              " 'อ': 382,\n",
              " 'แล้': 383,\n",
              " 'อาย': 384,\n",
              " 'ผู้': 385,\n",
              " 'มาจาก': 386,\n",
              " 'หมอ': 387,\n",
              " 'เริ่ม': 388,\n",
              " 'ด้วยกัน': 389,\n",
              " 'หลาน': 390,\n",
              " 'ร้าย': 391,\n",
              " 'เงียบ': 392,\n",
              " 'แล้วก็': 393,\n",
              " 'สุดยอด': 394,\n",
              " 'ตลก': 395,\n",
              " 'เข้ามา': 396,\n",
              " 'เฉย': 397,\n",
              " 'มีเงิน': 398,\n",
              " 'ตอนนี้': 399,\n",
              " 'หลัง': 400,\n",
              " 'เจ๊': 401,\n",
              " 'เห็นใจ': 402,\n",
              " 'ทำตัว': 403,\n",
              " 'สามี': 404,\n",
              " 'เล่า': 405,\n",
              " 'มีสิทธิ์': 406,\n",
              " 'เปิด': 407,\n",
              " 'แก่': 408,\n",
              " 'เเต่': 409,\n",
              " 'เนาะ': 410,\n",
              " 'เก่า': 411,\n",
              " 'ง่ายๆ': 412,\n",
              " 'พยายาม': 413,\n",
              " 'เห้อ': 414,\n",
              " 'ต่าย': 415,\n",
              " 'ชัย': 416,\n",
              " 'อิ': 417,\n",
              " 'เอ้ย': 418,\n",
              " 'ล่าง': 419,\n",
              " 'วัน': 420,\n",
              " 'เมื่อ': 421,\n",
              " 'ป': 422,\n",
              " 'ต่าง': 423,\n",
              " 'โหน': 424,\n",
              " 'ชัด': 425,\n",
              " 'เก๋': 426,\n",
              " 'รับเงิน': 427,\n",
              " 'พูดแทรก': 428,\n",
              " 'บริษัท': 429,\n",
              " 'โดย': 430,\n",
              " 'ดัน': 431,\n",
              " 'ยา': 432,\n",
              " 'เมียหลวง': 433,\n",
              " 'รุ้': 434,\n",
              " 'เล่น': 435,\n",
              " 'ใจดี': 436,\n",
              " 'สอน': 437,\n",
              " 'ภรรยา': 438,\n",
              " 'ลอง': 439,\n",
              " 'ประเทศ': 440,\n",
              " 'ผ่าน': 441,\n",
              " 'รั่ว': 442,\n",
              " 'เลิกกัน': 443,\n",
              " 'ข่าว': 444,\n",
              " 'หน้าตัวเมีย': 445,\n",
              " 'ตัง': 446,\n",
              " 'โทษ': 447,\n",
              " 'สัญญา': 448,\n",
              " 'คนดี': 449,\n",
              " 'เนอะ': 450,\n",
              " 'แปลก': 451,\n",
              " 'เคส': 452,\n",
              " 'กี่': 453,\n",
              " 'หนึ่ง': 454,\n",
              " 'บ': 455,\n",
              " 'ยังมี': 456,\n",
              " 'ชั่ว': 457,\n",
              " 'วจะ': 458,\n",
              " 'เมียน้อย': 459,\n",
              " 'จิต': 460,\n",
              " 'ความจริง': 461,\n",
              " 'ต่อไป': 462,\n",
              " 'เดือน': 463,\n",
              " 'ฉลาด': 464,\n",
              " 'ไหว': 465,\n",
              " 'ทั้งคู่': 466,\n",
              " 'สาม': 467,\n",
              " 'ดูแล': 468,\n",
              " 'นอน': 469,\n",
              " 'ก': 470,\n",
              " 'อันนี้': 471,\n",
              " 'แจ้งความ': 472,\n",
              " 'กรรม': 473,\n",
              " 'ตา': 474,\n",
              " 'ขอบคุณ': 475,\n",
              " 'พิธีกร': 476,\n",
              " 'อ้าง': 477,\n",
              " 'ให้ได้': 478,\n",
              " 'รอ': 479,\n",
              " 'ส่วนตัว': 480,\n",
              " 'ปวดหัว': 481,\n",
              " 'ตรรกะ': 482,\n",
              " 'อ้อย': 483,\n",
              " 'รู้จัก': 484,\n",
              " 'ข้าง': 485,\n",
              " 'ดีแล้ว': 486,\n",
              " 'ขุด': 487,\n",
              " 'ดิ': 488,\n",
              " 'รวย': 489,\n",
              " 'จดทะเบียน': 490,\n",
              " 'เรื่อย': 491,\n",
              " 'สร้าง': 492,\n",
              " 'เอาเรื่อง': 493,\n",
              " 'ว': 494,\n",
              " 'โมโห': 495,\n",
              " 'นั่น': 496,\n",
              " 'คุ': 497,\n",
              " 'กระแส': 498,\n",
              " 'เทป': 499,\n",
              " 'แรก': 500,\n",
              " 'ต่ำ': 501,\n",
              " 'ทะเลาะ': 502,\n",
              " 'หน่วง': 503,\n",
              " 'รอด': 504,\n",
              " 'เสียง': 505,\n",
              " 'โยน': 506,\n",
              " 'ทั้งหมด': 507,\n",
              " 'สภาพ': 508,\n",
              " 'คำถาม': 509,\n",
              " 'ติด': 510,\n",
              " 'ประจาน': 511,\n",
              " 'ย': 512,\n",
              " 'ไม่ค่อย': 513,\n",
              " 'จิตใจ': 514,\n",
              " 'แดนเซอร์': 515,\n",
              " 'ทั้งที่': 516,\n",
              " 'ตั้งใจ': 517,\n",
              " 'ดำ': 518,\n",
              " 'สูง': 519,\n",
              " 'ไปหา': 520,\n",
              " 'ใหญ่': 521,\n",
              " 'ไล่': 522,\n",
              " 'ต่อให้': 523,\n",
              " 'ทุเรศ': 524,\n",
              " 'การศึกษา': 525,\n",
              " 'พูดความจริง': 526,\n",
              " 'เท': 527,\n",
              " 'สงสัย': 528,\n",
              " 'เปน': 529,\n",
              " 'โลก': 530,\n",
              " 'สัตว์': 531,\n",
              " 'พูดว่า': 532,\n",
              " 'กฎหมาย': 533,\n",
              " 'แพง': 534,\n",
              " 'ออ': 535,\n",
              " 'ทำร้ายร่างกาย': 536,\n",
              " 'คนเรา': 537,\n",
              " 'อายุ': 538,\n",
              " 'ฏ': 539,\n",
              " 'ขี้': 540,\n",
              " 'น้า': 541,\n",
              " 'หรือเปล่า': 542,\n",
              " 'โหด': 543,\n",
              " 'พลาด': 544,\n",
              " 'ทั้งๆ': 545,\n",
              " 'หลง': 546,\n",
              " 'รักษา': 547,\n",
              " 'ขโมย': 548,\n",
              " 'คนเลว': 549,\n",
              " 'ๆๆๆ': 550,\n",
              " 'ดอก': 551,\n",
              " 'แท้ๆ': 552,\n",
              " 'น่ากลัว': 553,\n",
              " 'บิด': 554,\n",
              " 'สาระแน': 555,\n",
              " 'พูดจา': 556,\n",
              " 'ประจักษ์': 557,\n",
              " 'ทั้งสอง': 558,\n",
              " 'ดึง': 559,\n",
              " 'การกระทำ': 560,\n",
              " 'นี่แหละ': 561,\n",
              " 'กลับมา': 562,\n",
              " 'ทรง': 563,\n",
              " 'ด็อกเตอร์': 564,\n",
              " 'ฮา': 565,\n",
              " 'คัน': 566,\n",
              " 'แสน': 567,\n",
              " 'นิ': 568,\n",
              " 'คุก': 569,\n",
              " 'เห': 570,\n",
              " 'แดก': 571,\n",
              " 'หรือไม่': 572,\n",
              " 'รำคาญ': 573,\n",
              " 'ติดคุก': 574,\n",
              " 'ระวัง': 575,\n",
              " 'โยนความผิด': 576,\n",
              " 'สมัน': 577,\n",
              " 'ยืน': 578,\n",
              " 'สำหรับ': 579,\n",
              " 'เม้น': 580,\n",
              " 'แค่นี้': 581,\n",
              " 'กฏ': 582,\n",
              " 'ร': 583,\n",
              " 'อึดอัด': 584,\n",
              " 'เกิดขึ้น': 585,\n",
              " 'ทน': 586,\n",
              " 'ค': 587,\n",
              " 'คนบ้า': 588,\n",
              " 'ขับ': 589,\n",
              " 'ด': 590,\n",
              " 'ผิดที่': 591,\n",
              " 'แค้น': 592,\n",
              " 'อยากได้': 593,\n",
              " 'แรง': 594,\n",
              " 'ชัดเจน': 595,\n",
              " 'ต้องการ': 596,\n",
              " 'อาจ': 597,\n",
              " 'ชื่อ': 598,\n",
              " 'ไห': 599,\n",
              " 'แต่ละ': 600,\n",
              " 'ถือว่า': 601,\n",
              " 'กำลัง': 602,\n",
              " 'พา': 603,\n",
              " 'คนดัง': 604,\n",
              " 'ได้ใจ': 605,\n",
              " 'ตรงๆ': 606,\n",
              " 'เมา': 607,\n",
              " 'เสียเวลา': 608,\n",
              " 'คืน': 609,\n",
              " 'เหมือนเดิม': 610,\n",
              " 'จิง': 611,\n",
              " 'นึก': 612,\n",
              " 'แยก': 613,\n",
              " 'เข้าไป': 614,\n",
              " 'เดิน': 615,\n",
              " 'ลูกน้อง': 616,\n",
              " 'ขาว': 617,\n",
              " 'ครั้ง': 618,\n",
              " 'ปัญหา': 619,\n",
              " 'ทิ้ง': 620,\n",
              " 'ง่าย': 621,\n",
              " 'ประ': 622,\n",
              " 'ดูออก': 623,\n",
              " 'ควรจะ': 624,\n",
              " 'เจ้าของบ้าน': 625,\n",
              " 'เหตุ': 626,\n",
              " 'อั้ม': 627,\n",
              " 'เเล้ว': 628,\n",
              " 'สำคัญ': 629,\n",
              " 'ที่มา': 630,\n",
              " 'แก้ตัว': 631,\n",
              " 'ถุน': 632,\n",
              " 'บาง': 633,\n",
              " 'เกลียด': 634,\n",
              " 'ซะ': 635,\n",
              " 'คนใน': 636,\n",
              " 'สื่อ': 637,\n",
              " 'ยุ': 638,\n",
              " 'พ่อแม่': 639,\n",
              " 'เจ้': 640,\n",
              " 'ส่วย': 641,\n",
              " 'บางคน': 642,\n",
              " 'มอ': 643,\n",
              " 'กวน': 644,\n",
              " 'โทร': 645,\n",
              " 'มั้ง': 646,\n",
              " 'ขับรถ': 647,\n",
              " 'ได้รับ': 648,\n",
              " 'มนุษย์': 649,\n",
              " 'หนี': 650,\n",
              " 'พี่น้อง': 651,\n",
              " 'ภาพ': 652,\n",
              " 'อ่าน': 653,\n",
              " 'ทาส': 654,\n",
              " 'นี้แหละ': 655,\n",
              " 'หาเรื่อง': 656,\n",
              " 'คดี': 657,\n",
              " 'ยุ่ง': 658,\n",
              " 'น้องสาว': 659,\n",
              " 'มีเรื่อง': 660,\n",
              " 'แล้วแต่': 661,\n",
              " 'ปม': 662,\n",
              " 'แก้': 663,\n",
              " 'ใจร้าย': 664,\n",
              " 'ชื่นชม': 665,\n",
              " 'สนุก': 666,\n",
              " 'ปา': 667,\n",
              " 'มือ': 668,\n",
              " 'เรียกร้อง': 669,\n",
              " 'ฝาก': 670,\n",
              " 'แย่ง': 671,\n",
              " 'เหลือ': 672,\n",
              " 'กระ': 673,\n",
              " 'ลืม': 674,\n",
              " 'มีลูก': 675,\n",
              " 'อื่น': 676,\n",
              " 'เปลี่ยน': 677,\n",
              " 'อารมณ์': 678,\n",
              " 'พัง': 679,\n",
              " 'สบาย': 680,\n",
              " 'ไม่งั้น': 681,\n",
              " 'คู่': 682,\n",
              " 'ต้นเรื่อง': 683,\n",
              " 'ต้นเหตุ': 684,\n",
              " 'พุด': 685,\n",
              " 'เอ็น': 686,\n",
              " 'ทั้งนั้น': 687,\n",
              " 'สติ': 688,\n",
              " 'ถูกต้อง': 689,\n",
              " 'พร้อม': 690,\n",
              " 'ประชาชน': 691,\n",
              " 'เหตุการณ์': 692,\n",
              " 'มีปัญหา': 693,\n",
              " 'เงินเดือน': 694,\n",
              " 'อาชีพ': 695,\n",
              " 'ธรรมดา': 696,\n",
              " 'ดูดี': 697,\n",
              " 'ชน': 698,\n",
              " 'ริ': 699,\n",
              " 'เกินไป': 700,\n",
              " 'ตรวจสอบ': 701,\n",
              " 'วน': 702,\n",
              " 'หัวหมอ': 703,\n",
              " 'ไซ': 704,\n",
              " 'ออกจาก': 705,\n",
              " 'เกี่ยวกับ': 706,\n",
              " 'โรคจิต': 707,\n",
              " 'ซ้อน': 708,\n",
              " 'เห็นแก่ตัว': 709,\n",
              " 'ที่ไหน': 710,\n",
              " 'บุญ': 711,\n",
              " 'ร้อง': 712,\n",
              " 'แดง': 713,\n",
              " 'อก': 714,\n",
              " 'กลายเป็น': 715,\n",
              " 'โอ้ย': 716,\n",
              " 'ต่อย': 717,\n",
              " 'ทำเป็น': 718,\n",
              " 'สม': 719,\n",
              " 'ภาค': 720,\n",
              " 'เร': 721,\n",
              " 'คนไทย': 722,\n",
              " 'คนละ': 723,\n",
              " 'นั่นแหละ': 724,\n",
              " 'หนัง': 725,\n",
              " 'นั้นแหละ': 726,\n",
              " 'ย้อน': 727,\n",
              " 'เท่า': 728,\n",
              " 'เป้': 729,\n",
              " 'ดีแต่': 730,\n",
              " 'หึง': 731,\n",
              " 'ไร้': 732,\n",
              " 'ร้องไห้': 733,\n",
              " 'พูดไม่รู้เรื่อง': 734,\n",
              " 'โกรธ': 735,\n",
              " 'แทรก': 736,\n",
              " 'ชาวบ้าน': 737,\n",
              " 'ให้อภัย': 738,\n",
              " 'เดียวกัน': 739,\n",
              " 'แล้วไป': 740,\n",
              " 'เต็มๆ': 741,\n",
              " 'เครียด': 742,\n",
              " 'ตั้งแต่แรก': 743,\n",
              " 'อาการ': 744,\n",
              " 'กระทำ': 745,\n",
              " 'ห': 746,\n",
              " 'งั้น': 747,\n",
              " 'ป่ะ': 748,\n",
              " 'ผี': 749,\n",
              " 'จึง': 750,\n",
              " 'ใด': 751,\n",
              " 'สัน': 752,\n",
              " 'เจ้าของ': 753,\n",
              " 'โกง': 754,\n",
              " 'แซว': 755,\n",
              " 'งก': 756,\n",
              " 'แสดงว่า': 757,\n",
              " 'โพส': 758,\n",
              " 'ความรู้สึก': 759,\n",
              " 'พวกคุณ': 760,\n",
              " 'เรื่องจริง': 761,\n",
              " 'อย่างนี้': 762,\n",
              " 'แย่มาก': 763,\n",
              " 'บัญชี': 764,\n",
              " 'ทัน': 765,\n",
              " 'แตก': 766,\n",
              " 'ทั้งคน': 767,\n",
              " 'คนดู': 768,\n",
              " 'บาท': 769,\n",
              " 'พึ่ง': 770,\n",
              " 'ถึงที่สุด': 771,\n",
              " 'จำ': 772,\n",
              " 'ขัด': 773,\n",
              " 'ห่า': 774,\n",
              " 'ตีน': 775,\n",
              " 'หวัง': 776,\n",
              " 'คนรัก': 777,\n",
              " 'เมตตา': 778,\n",
              " 'แห': 779,\n",
              " 'มองว่า': 780,\n",
              " 'อ้างว่า': 781,\n",
              " 'โอเค': 782,\n",
              " 'เหล้า': 783,\n",
              " 'ขาด': 784,\n",
              " 'น้ำ': 785,\n",
              " 'นัก': 786,\n",
              " 'ลูกค้า': 787,\n",
              " 'ศาล': 788,\n",
              " 'สมัยนี้': 789,\n",
              " 'ใด้': 790,\n",
              " 'ความผิด': 791,\n",
              " 'ลย': 792,\n",
              " 'เต็ม': 793,\n",
              " 'บ่': 794,\n",
              " 'เหนื่อย': 795,\n",
              " 'ขี้โกง': 796,\n",
              " 'ยึด': 797,\n",
              " 'รี': 798,\n",
              " 'เซอร์': 799,\n",
              " 'แสดง': 800,\n",
              " 'มุม': 801,\n",
              " 'อนาคต': 802,\n",
              " 'ให้กำลังใจ': 803,\n",
              " 'อันตราย': 804,\n",
              " 'โมนะ': 805,\n",
              " 'วางแผน': 806,\n",
              " 'น้ำตา': 807,\n",
              " 'จดทะเบียนสมรส': 808,\n",
              " 'ใช้ชีวิต': 809,\n",
              " 'ช่วง': 810,\n",
              " 'ครับผม': 811,\n",
              " 'นาที': 812,\n",
              " 'ทำสัญญา': 813,\n",
              " 'รอบ': 814,\n",
              " 'หวย': 815,\n",
              " 'เรื่องส่วนตัว': 816,\n",
              " 'ทุกวันนี้': 817,\n",
              " 'เดิม': 818,\n",
              " 'จด': 819,\n",
              " 'ล': 820,\n",
              " 'วง': 821,\n",
              " 'แบ่ง': 822,\n",
              " 'หัก': 823,\n",
              " 'ตะกุกตะกัก': 824,\n",
              " 'เคลียร์': 825,\n",
              " 'คนไข้': 826,\n",
              " 'หลอกลวง': 827,\n",
              " 'วิ่ง': 828,\n",
              " 'แทนที่จะ': 829,\n",
              " 'รับผิดชอบ': 830,\n",
              " 'ผล': 831,\n",
              " 'เมื่อวาน': 832,\n",
              " 'เอาจริง': 833,\n",
              " 'ปลา': 834,\n",
              " 'เหยื่อ': 835,\n",
              " 'นับถือ': 836,\n",
              " 'อยู่ดี': 837,\n",
              " 'หักหลัง': 838,\n",
              " 'เจตนา': 839,\n",
              " 'สาระ': 840,\n",
              " 'เนี้ย': 841,\n",
              " 'ใดๆ': 842,\n",
              " 'ตอนแรก': 843,\n",
              " 'ลูกผู้ชาย': 844,\n",
              " 'ค่อย': 845,\n",
              " 'สะ': 846,\n",
              " 'คุณแม่': 847,\n",
              " 'ช่าง': 848,\n",
              " 'แถว': 849,\n",
              " 'ลุ': 850,\n",
              " 'เเบบ': 851,\n",
              " 'ภาษี': 852,\n",
              " 'เท่านั้น': 853,\n",
              " 'ซื้อ': 854,\n",
              " 'ข้อมูล': 855,\n",
              " 'เลน': 856,\n",
              " 'เดือดร้อน': 857,\n",
              " 'ทะเบียนสมรส': 858,\n",
              " 'เหตุผล': 859,\n",
              " 'คบไม่ได้': 860,\n",
              " 'หมาหมู่': 861,\n",
              " 'ระ': 862,\n",
              " 'เอาตัวรอด': 863,\n",
              " 'เพราะว่า': 864,\n",
              " 'มีสติ': 865,\n",
              " 'จ้ะ': 866,\n",
              " 'ผุ้': 867,\n",
              " 'พฤติกรรม': 868,\n",
              " 'ศิลปิน': 869,\n",
              " 'สนใจ': 870,\n",
              " 'ไว': 871,\n",
              " 'อยุ่': 872,\n",
              " 'หัวใจ': 873,\n",
              " 'เวร': 874,\n",
              " 'ใช่ไหม': 875,\n",
              " 'เต้น': 876,\n",
              " 'ยก': 877,\n",
              " 'เกือบ': 878,\n",
              " 'จัดการ': 879,\n",
              " 'นอก': 880,\n",
              " 'ขาย': 881,\n",
              " 'กล้อง': 882,\n",
              " 'สวน': 883,\n",
              " 'มั่นใจ': 884,\n",
              " 'คอย': 885,\n",
              " 'เวรกรรม': 886,\n",
              " 'พัน': 887,\n",
              " 'ทรัพย์': 888,\n",
              " 'ญาติ': 889,\n",
              " 'กา': 890,\n",
              " 'กด': 891,\n",
              " 'ลงมา': 892,\n",
              " 'ตะ': 893,\n",
              " 'อ่อน': 894,\n",
              " 'ลูกหลาน': 895,\n",
              " 'อี่': 896,\n",
              " 'เงี่ยน': 897,\n",
              " 'จริงใจ': 898,\n",
              " 'เท่าที่': 899,\n",
              " 'ความรุนแรง': 900,\n",
              " 'เริ่มต้น': 901,\n",
              " 'ที่รัก': 902,\n",
              " 'ปัญญา': 903,\n",
              " 'ลบ': 904,\n",
              " 'เป็นการ': 905,\n",
              " 'ข้อ': 906,\n",
              " 'จิงๆ': 907,\n",
              " 'ดูเหมือน': 908,\n",
              " 'แซะ': 909,\n",
              " 'ท': 910,\n",
              " 'เงียบๆ': 911,\n",
              " 'มอไซค์': 912,\n",
              " 'พระ': 913,\n",
              " 'บี': 914,\n",
              " 'แม้': 915,\n",
              " 'บน': 916,\n",
              " 'ทั้งสองฝ่าย': 917,\n",
              " 'สะใจ': 918,\n",
              " 'นึกถึง': 919,\n",
              " 'สิทธิ': 920,\n",
              " 'ตก': 921,\n",
              " 'โชคดี': 922,\n",
              " 'เอ็ง': 923,\n",
              " 'มากมาย': 924,\n",
              " 'ตกลง': 925,\n",
              " 'ผู้ใหญ่': 926,\n",
              " 'ให้โอกาส': 927,\n",
              " 'ไค': 928,\n",
              " 'เส': 929,\n",
              " 'เตรียม': 930,\n",
              " 'สาย': 931,\n",
              " 'เละ': 932,\n",
              " 'รา': 933,\n",
              " 'มีชื่อเสียง': 934,\n",
              " 'ระดับ': 935,\n",
              " 'ร้อย': 936,\n",
              " 'เผลอ': 937,\n",
              " 'จุด': 938,\n",
              " 'เสมอ': 939,\n",
              " 'วกไปวนมา': 940,\n",
              " 'คงจะ': 941,\n",
              " 'ซื่อ': 942,\n",
              " 'ล้อ': 943,\n",
              " 'คิดได้': 944,\n",
              " 'แพ้': 945,\n",
              " 'เผา': 946,\n",
              " 'กลุ่ม': 947,\n",
              " 'ไฟไหม้': 948,\n",
              " 'ไล่ออก': 949,\n",
              " 'รพ': 950,\n",
              " 'เบื่อ': 951,\n",
              " 'น่ารำคาญ': 952,\n",
              " 'นรก': 953,\n",
              " 'ชู้': 954,\n",
              " 'ระยำ': 955,\n",
              " 'กระจอก': 956,\n",
              " 'สี่': 957,\n",
              " 'ทา': 958,\n",
              " 'ใบ': 959,\n",
              " 'ต่างกัน': 960,\n",
              " 'ที่ว่า': 961,\n",
              " 'จ': 962,\n",
              " 'ลอยตัว': 963,\n",
              " 'หัวเราะ': 964,\n",
              " 'ชิป': 965,\n",
              " 'รูป': 966,\n",
              " 'แดนซ์': 967,\n",
              " 'ชมพู': 968,\n",
              " 'ซัก': 969,\n",
              " 'เป็นผู้ใหญ่': 970,\n",
              " 'เพื่อให้': 971,\n",
              " 'บางที': 972,\n",
              " 'เกรด': 973,\n",
              " 'เจ็บปวด': 974,\n",
              " 'ทีม': 975,\n",
              " 'วาง': 976,\n",
              " 'ควาย': 977,\n",
              " 'แต่ละคน': 978,\n",
              " 'ชนะ': 979,\n",
              " 'ได้ขนาด': 980,\n",
              " 'คนรวย': 981,\n",
              " 'ทุกวัน': 982,\n",
              " 'พอใจ': 983,\n",
              " 'ยิ่งกว่า': 984,\n",
              " 'ชา': 985,\n",
              " 'ๆคน': 986,\n",
              " 'ลึก': 987,\n",
              " 'เถียง': 988,\n",
              " 'ประมาณ': 989,\n",
              " 'มักจะ': 990,\n",
              " 'ทองคำ': 991,\n",
              " 'ซิ': 992,\n",
              " 'รับรู้': 993,\n",
              " 'ตัด': 994,\n",
              " 'ไหม้': 995,\n",
              " 'ทำลาย': 996,\n",
              " 'ดับ': 997,\n",
              " 'โสด': 998,\n",
              " 'ผู้เสียหาย': 999,\n",
              " 'ได้มา': 1000,\n",
              " ...}"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_word_tokenizer = create_tokenizer(cleaned_words)\n",
        "vocab_size = len(train_word_tokenizer.word_index) + 1\n",
        "\n",
        "train_word_tokenizer.word_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3yqBv-a1MLz"
      },
      "outputs": [],
      "source": [
        "def max_length(words):\n",
        "    return(len(max(words, key = len)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-nEnWjx1Pc4",
        "outputId": "7af15e7d-c517-48a7-ff10-3b67e1102d31"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "231"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "max_length = max_length(temp)\n",
        "max_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fX9GbiAq1RUN"
      },
      "outputs": [],
      "source": [
        "def encoding_doc(token, words):\n",
        "    return(token.texts_to_sequences(words))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQTSYIj01TZ5",
        "outputId": "a1a3efab-719d-4c89-e869-33409173680a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ได้ สอง ล้าน เป็น ฉัน ดีใจ มาก ได้ เงินได้ ทิ้ง คนเจ้าชู้ ได้ ชีวิต ใหม่ ฉัน จะ อยู่ เงียบ เงียบ สวย สวย หา แฟน ใหม่\n",
            "[13, 238, 107, 11, 304, 1452, 21, 13, 2214, 620, 4210, 13, 168, 231, 304, 7, 54, 392, 392, 219, 219, 210, 94, 231]\n"
          ]
        }
      ],
      "source": [
        "encoded_doc = encoding_doc(train_word_tokenizer, cleaned_words)\n",
        "\n",
        "print(cleaned_words[0])\n",
        "print(encoded_doc[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qpnFHOKE1U53"
      },
      "outputs": [],
      "source": [
        "def padding_doc(encoded_doc, max_length):\n",
        "    return(pad_sequences(encoded_doc, maxlen = max_length, padding = \"post\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3ySY9151X6h",
        "outputId": "1ff92658-5ef6-44a3-cb0b-344ceeb789c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of padded docs =  (5200, 231)\n",
            "ได้ สอง ล้าน เป็น ฉัน ดีใจ มาก ได้ เงินได้ ทิ้ง คนเจ้าชู้ ได้ ชีวิต ใหม่ ฉัน จะ อยู่ เงียบ เงียบ สวย สวย หา แฟน ใหม่\n",
            "[13, 238, 107, 11, 304, 1452, 21, 13, 2214, 620, 4210, 13, 168, 231, 304, 7, 54, 392, 392, 219, 219, 210, 94, 231]\n",
            "[  13  238  107   11  304 1452   21   13 2214  620 4210   13  168  231\n",
            "  304    7   54  392  392  219  219  210   94  231    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0]\n"
          ]
        }
      ],
      "source": [
        "padded_doc = padding_doc(encoded_doc, max_length)\n",
        "print(\"Shape of padded docs = \",padded_doc.shape)\n",
        "\n",
        "print(cleaned_words[0])\n",
        "print(encoded_doc[0])\n",
        "print(padded_doc[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJaB4_Hg1ZZ2",
        "outputId": "49d8689a-9ee1-4a1b-870e-34c64a50e5f4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['hig', 'pos', 'neg', 'bly']"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "unique_category = list(set(category))\n",
        "unique_category"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQO14SNX1b-z"
      },
      "outputs": [],
      "source": [
        "output_tokenizer = create_tokenizer(unique_category)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfcgTpkg1dnB",
        "outputId": "40cf31aa-76ec-468e-cc17-3f8d54990a62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['pos' 'pos']\n",
            "[[2], [2]]\n"
          ]
        }
      ],
      "source": [
        "encoded_output = encoding_doc(output_tokenizer, category)\n",
        "print(category[0:2])\n",
        "print(encoded_output[0:2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Db9D9aJo1fUg",
        "outputId": "307501a1-aaa3-47f6-cde1-3016b716d016"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(5200, 1)"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "encoded_output = np.array(encoded_output).reshape(len(encoded_output), 1)\n",
        "encoded_output.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FE2mwEG01iv2"
      },
      "outputs": [],
      "source": [
        "def one_hot(encode):\n",
        "  oh = OneHotEncoder(sparse_output=False)\n",
        "  return(oh.fit_transform(encode))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sp4joKbA1k9Y",
        "outputId": "623a2cd6-7e98-4f1a-cf24-8eeb456b996a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2]\n",
            "[0. 1. 0. 0.]\n"
          ]
        }
      ],
      "source": [
        "output_one_hot = one_hot(encoded_output)\n",
        "print(encoded_output[0])\n",
        "print(output_one_hot[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0b750YED1mx5"
      },
      "outputs": [],
      "source": [
        "train_X, val_X, train_Y, val_Y = train_test_split(padded_doc, output_one_hot, shuffle = True, test_size = 0.2, stratify=output_one_hot)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpjdbaME1qjv",
        "outputId": "982b45d1-33f2-4d07-e5f4-d834284ea010"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of train_X = (4160, 231) and train_Y = (4160, 4)\n",
            "Shape of val_X = (1040, 231) and val_Y = (1040, 4)\n"
          ]
        }
      ],
      "source": [
        "print(\"Shape of train_X = %s and train_Y = %s\" % (train_X.shape, train_Y.shape))\n",
        "print(\"Shape of val_X = %s and val_Y = %s\" % (val_X.shape, val_Y.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q3ZoNcuY1tN9"
      },
      "outputs": [],
      "source": [
        "num_classes = len(unique_category)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_ifL8y01wQo"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, GRU, LSTM, Bidirectional, Embedding, Dropout, BatchNormalization\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.layers import InputLayer\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "adam = Adam(learning_rate=0.00001)\n",
        "\n",
        "def create_model(vocab_size, max_length):\n",
        "  model = Sequential()\n",
        "  model.add(InputLayer(shape=(max_length,)))\n",
        "  model.add(Embedding(vocab_size, 128,  trainable = True))\n",
        "  model.add(Bidirectional(LSTM(128),merge_mode=\"concat\"))\n",
        "  model.add(Dense(128, activation = \"relu\"))\n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(Dense(64, activation = \"relu\"))\n",
        "  model.add(Dropout(0.3))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dense(num_classes, activation = \"softmax\"))\n",
        "\n",
        "  return model\n",
        "\n",
        "model = create_model(vocab_size, max_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "UM9LnZOy14vP",
        "outputId": "eebef974-2559-4797-cfe1-ea02ac2a685c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">231</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">980,224</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">260</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m231\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m980,224\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │         \u001b[38;5;34m263,168\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m32,896\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │             \u001b[38;5;34m260\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,285,060</span> (4.90 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,285,060\u001b[0m (4.90 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,284,932</span> (4.90 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,284,932\u001b[0m (4.90 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> (512.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m128\u001b[0m (512.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.compile(loss = \"categorical_crossentropy\", optimizer = adam, metrics = [\"accuracy\"])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CACYChD-18-t"
      },
      "outputs": [],
      "source": [
        "filename = 'model.keras'\n",
        "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1-R1GYb1_u0",
        "outputId": "624e0588-56a5-4a9a-ee11-b2bba95d5890"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.2589 - loss: 1.4183\n",
            "Epoch 1: val_loss improved from inf to 1.38444, saving model to model.keras\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 28ms/step - accuracy: 0.2589 - loss: 1.4183 - val_accuracy: 0.3019 - val_loss: 1.3844\n",
            "Epoch 2/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.2696 - loss: 1.3936\n",
            "Epoch 2: val_loss improved from 1.38444 to 1.37716, saving model to model.keras\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 25ms/step - accuracy: 0.2696 - loss: 1.3936 - val_accuracy: 0.3202 - val_loss: 1.3772\n",
            "Epoch 3/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.2828 - loss: 1.3858\n",
            "Epoch 3: val_loss improved from 1.37716 to 1.36427, saving model to model.keras\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - accuracy: 0.2829 - loss: 1.3857 - val_accuracy: 0.3269 - val_loss: 1.3643\n",
            "Epoch 4/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.2948 - loss: 1.3707\n",
            "Epoch 4: val_loss improved from 1.36427 to 1.35448, saving model to model.keras\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - accuracy: 0.2948 - loss: 1.3706 - val_accuracy: 0.3385 - val_loss: 1.3545\n",
            "Epoch 5/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.3150 - loss: 1.3609\n",
            "Epoch 5: val_loss improved from 1.35448 to 1.34588, saving model to model.keras\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 27ms/step - accuracy: 0.3150 - loss: 1.3609 - val_accuracy: 0.3596 - val_loss: 1.3459\n",
            "Epoch 6/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.3427 - loss: 1.3440\n",
            "Epoch 6: val_loss improved from 1.34588 to 1.33444, saving model to model.keras\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.3428 - loss: 1.3440 - val_accuracy: 0.3654 - val_loss: 1.3344\n",
            "Epoch 7/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.3354 - loss: 1.3466\n",
            "Epoch 7: val_loss improved from 1.33444 to 1.32254, saving model to model.keras\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 25ms/step - accuracy: 0.3354 - loss: 1.3466 - val_accuracy: 0.3769 - val_loss: 1.3225\n",
            "Epoch 8/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.3520 - loss: 1.3328\n",
            "Epoch 8: val_loss improved from 1.32254 to 1.30922, saving model to model.keras\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 25ms/step - accuracy: 0.3521 - loss: 1.3328 - val_accuracy: 0.3962 - val_loss: 1.3092\n",
            "Epoch 9/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.3934 - loss: 1.3063\n",
            "Epoch 9: val_loss improved from 1.30922 to 1.29491, saving model to model.keras\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 29ms/step - accuracy: 0.3933 - loss: 1.3063 - val_accuracy: 0.4058 - val_loss: 1.2949\n",
            "Epoch 10/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.3968 - loss: 1.2815\n",
            "Epoch 10: val_loss improved from 1.29491 to 1.27580, saving model to model.keras\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - accuracy: 0.3969 - loss: 1.2815 - val_accuracy: 0.4221 - val_loss: 1.2758\n",
            "Epoch 11/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.4155 - loss: 1.2745\n",
            "Epoch 11: val_loss improved from 1.27580 to 1.25532, saving model to model.keras\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.4155 - loss: 1.2745 - val_accuracy: 0.4356 - val_loss: 1.2553\n",
            "Epoch 12/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.4421 - loss: 1.2347\n",
            "Epoch 12: val_loss improved from 1.25532 to 1.23190, saving model to model.keras\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.4421 - loss: 1.2347 - val_accuracy: 0.4385 - val_loss: 1.2319\n",
            "Epoch 13/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.4616 - loss: 1.2103\n",
            "Epoch 13: val_loss improved from 1.23190 to 1.20772, saving model to model.keras\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.4616 - loss: 1.2103 - val_accuracy: 0.4692 - val_loss: 1.2077\n",
            "Epoch 14/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.4883 - loss: 1.1852\n",
            "Epoch 14: val_loss improved from 1.20772 to 1.18610, saving model to model.keras\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 0.4883 - loss: 1.1852 - val_accuracy: 0.4635 - val_loss: 1.1861\n",
            "Epoch 15/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5074 - loss: 1.1483\n",
            "Epoch 15: val_loss improved from 1.18610 to 1.15163, saving model to model.keras\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.5074 - loss: 1.1482 - val_accuracy: 0.4913 - val_loss: 1.1516\n",
            "Epoch 16/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5203 - loss: 1.1137\n",
            "Epoch 16: val_loss improved from 1.15163 to 1.12540, saving model to model.keras\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 25ms/step - accuracy: 0.5203 - loss: 1.1137 - val_accuracy: 0.4798 - val_loss: 1.1254\n",
            "Epoch 17/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5473 - loss: 1.0615\n",
            "Epoch 17: val_loss improved from 1.12540 to 1.09607, saving model to model.keras\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.5474 - loss: 1.0615 - val_accuracy: 0.4971 - val_loss: 1.0961\n",
            "Epoch 18/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5591 - loss: 1.0321\n",
            "Epoch 18: val_loss improved from 1.09607 to 1.09378, saving model to model.keras\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 0.5591 - loss: 1.0320 - val_accuracy: 0.5221 - val_loss: 1.0938\n",
            "Epoch 19/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5930 - loss: 0.9687\n",
            "Epoch 19: val_loss improved from 1.09378 to 1.04537, saving model to model.keras\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.5930 - loss: 0.9689 - val_accuracy: 0.5490 - val_loss: 1.0454\n",
            "Epoch 20/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6092 - loss: 0.9520\n",
            "Epoch 20: val_loss improved from 1.04537 to 1.02596, saving model to model.keras\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 25ms/step - accuracy: 0.6092 - loss: 0.9520 - val_accuracy: 0.5519 - val_loss: 1.0260\n",
            "Epoch 21/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6224 - loss: 0.9209\n",
            "Epoch 21: val_loss improved from 1.02596 to 1.00505, saving model to model.keras\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.6224 - loss: 0.9208 - val_accuracy: 0.5702 - val_loss: 1.0051\n",
            "Epoch 22/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6261 - loss: 0.9123\n",
            "Epoch 22: val_loss did not improve from 1.00505\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.6262 - loss: 0.9122 - val_accuracy: 0.5596 - val_loss: 1.0210\n",
            "Epoch 23/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6677 - loss: 0.8487\n",
            "Epoch 23: val_loss improved from 1.00505 to 0.96611, saving model to model.keras\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.6677 - loss: 0.8487 - val_accuracy: 0.5952 - val_loss: 0.9661\n",
            "Epoch 24/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6716 - loss: 0.8228\n",
            "Epoch 24: val_loss did not improve from 0.96611\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.6716 - loss: 0.8228 - val_accuracy: 0.5846 - val_loss: 0.9778\n",
            "Epoch 25/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6744 - loss: 0.8196\n",
            "Epoch 25: val_loss improved from 0.96611 to 0.93508, saving model to model.keras\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.6746 - loss: 0.8194 - val_accuracy: 0.6038 - val_loss: 0.9351\n",
            "Epoch 26/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7156 - loss: 0.7487\n",
            "Epoch 26: val_loss did not improve from 0.93508\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.7154 - loss: 0.7488 - val_accuracy: 0.5942 - val_loss: 0.9388\n",
            "Epoch 27/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7107 - loss: 0.7510\n",
            "Epoch 27: val_loss improved from 0.93508 to 0.90538, saving model to model.keras\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.7107 - loss: 0.7509 - val_accuracy: 0.6231 - val_loss: 0.9054\n",
            "Epoch 28/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6906 - loss: 0.7620\n",
            "Epoch 28: val_loss improved from 0.90538 to 0.90092, saving model to model.keras\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.6907 - loss: 0.7619 - val_accuracy: 0.6163 - val_loss: 0.9009\n",
            "Epoch 29/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7277 - loss: 0.7012\n",
            "Epoch 29: val_loss improved from 0.90092 to 0.88057, saving model to model.keras\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - accuracy: 0.7278 - loss: 0.7011 - val_accuracy: 0.6298 - val_loss: 0.8806\n",
            "Epoch 30/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7678 - loss: 0.6364\n",
            "Epoch 30: val_loss improved from 0.88057 to 0.86325, saving model to model.keras\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 25ms/step - accuracy: 0.7677 - loss: 0.6364 - val_accuracy: 0.6510 - val_loss: 0.8632\n",
            "Epoch 31/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7427 - loss: 0.6610\n",
            "Epoch 31: val_loss improved from 0.86325 to 0.85299, saving model to model.keras\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.7428 - loss: 0.6608 - val_accuracy: 0.6683 - val_loss: 0.8530\n",
            "Epoch 32/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7683 - loss: 0.6163\n",
            "Epoch 32: val_loss improved from 0.85299 to 0.84427, saving model to model.keras\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.7684 - loss: 0.6163 - val_accuracy: 0.6567 - val_loss: 0.8443\n",
            "Epoch 33/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7995 - loss: 0.5911\n",
            "Epoch 33: val_loss improved from 0.84427 to 0.83912, saving model to model.keras\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - accuracy: 0.7995 - loss: 0.5911 - val_accuracy: 0.6596 - val_loss: 0.8391\n",
            "Epoch 34/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8025 - loss: 0.5698\n",
            "Epoch 34: val_loss did not improve from 0.83912\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.8026 - loss: 0.5697 - val_accuracy: 0.6654 - val_loss: 0.8787\n",
            "Epoch 35/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8127 - loss: 0.5385\n",
            "Epoch 35: val_loss improved from 0.83912 to 0.82186, saving model to model.keras\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 0.8127 - loss: 0.5385 - val_accuracy: 0.6817 - val_loss: 0.8219\n",
            "Epoch 36/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8271 - loss: 0.5214\n",
            "Epoch 36: val_loss improved from 0.82186 to 0.81552, saving model to model.keras\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.8271 - loss: 0.5214 - val_accuracy: 0.7010 - val_loss: 0.8155\n",
            "Epoch 37/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8413 - loss: 0.4960\n",
            "Epoch 37: val_loss improved from 0.81552 to 0.81018, saving model to model.keras\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.8413 - loss: 0.4960 - val_accuracy: 0.6971 - val_loss: 0.8102\n",
            "Epoch 38/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8307 - loss: 0.4850\n",
            "Epoch 38: val_loss did not improve from 0.81018\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.8308 - loss: 0.4849 - val_accuracy: 0.6990 - val_loss: 0.8119\n",
            "Epoch 39/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8617 - loss: 0.4347\n",
            "Epoch 39: val_loss improved from 0.81018 to 0.80064, saving model to model.keras\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.8616 - loss: 0.4349 - val_accuracy: 0.7067 - val_loss: 0.8006\n",
            "Epoch 40/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8580 - loss: 0.4411\n",
            "Epoch 40: val_loss did not improve from 0.80064\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 25ms/step - accuracy: 0.8581 - loss: 0.4411 - val_accuracy: 0.7067 - val_loss: 0.8036\n",
            "Epoch 41/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8656 - loss: 0.4204\n",
            "Epoch 41: val_loss did not improve from 0.80064\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - accuracy: 0.8657 - loss: 0.4204 - val_accuracy: 0.7058 - val_loss: 0.8010\n",
            "Epoch 42/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8813 - loss: 0.4073\n",
            "Epoch 42: val_loss did not improve from 0.80064\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.8812 - loss: 0.4073 - val_accuracy: 0.6760 - val_loss: 0.8349\n",
            "Epoch 43/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8876 - loss: 0.3727\n",
            "Epoch 43: val_loss improved from 0.80064 to 0.79413, saving model to model.keras\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.8877 - loss: 0.3727 - val_accuracy: 0.7125 - val_loss: 0.7941\n",
            "Epoch 44/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9065 - loss: 0.3463\n",
            "Epoch 44: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 0.9064 - loss: 0.3464 - val_accuracy: 0.6779 - val_loss: 0.8521\n",
            "Epoch 45/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8997 - loss: 0.3640\n",
            "Epoch 45: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.8998 - loss: 0.3639 - val_accuracy: 0.7048 - val_loss: 0.8053\n",
            "Epoch 46/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9124 - loss: 0.3258\n",
            "Epoch 46: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9123 - loss: 0.3259 - val_accuracy: 0.7096 - val_loss: 0.8040\n",
            "Epoch 47/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9089 - loss: 0.3249\n",
            "Epoch 47: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9088 - loss: 0.3250 - val_accuracy: 0.7087 - val_loss: 0.8220\n",
            "Epoch 48/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9310 - loss: 0.2845\n",
            "Epoch 48: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.9310 - loss: 0.2845 - val_accuracy: 0.6846 - val_loss: 0.8472\n",
            "Epoch 49/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9110 - loss: 0.3015\n",
            "Epoch 49: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 0.9111 - loss: 0.3014 - val_accuracy: 0.7067 - val_loss: 0.8265\n",
            "Epoch 50/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9323 - loss: 0.2869\n",
            "Epoch 50: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.9323 - loss: 0.2869 - val_accuracy: 0.7154 - val_loss: 0.8181\n",
            "Epoch 51/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9417 - loss: 0.2610\n",
            "Epoch 51: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9416 - loss: 0.2611 - val_accuracy: 0.7183 - val_loss: 0.8275\n",
            "Epoch 52/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9306 - loss: 0.2591\n",
            "Epoch 52: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9307 - loss: 0.2591 - val_accuracy: 0.7183 - val_loss: 0.8169\n",
            "Epoch 53/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9321 - loss: 0.2516\n",
            "Epoch 53: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.9322 - loss: 0.2515 - val_accuracy: 0.7173 - val_loss: 0.8546\n",
            "Epoch 54/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9449 - loss: 0.2221\n",
            "Epoch 54: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.9449 - loss: 0.2221 - val_accuracy: 0.7106 - val_loss: 0.8352\n",
            "Epoch 55/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9450 - loss: 0.2350\n",
            "Epoch 55: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.9450 - loss: 0.2350 - val_accuracy: 0.7058 - val_loss: 0.8505\n",
            "Epoch 56/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9534 - loss: 0.2052\n",
            "Epoch 56: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9534 - loss: 0.2053 - val_accuracy: 0.7067 - val_loss: 0.8626\n",
            "Epoch 57/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9488 - loss: 0.2147\n",
            "Epoch 57: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9488 - loss: 0.2147 - val_accuracy: 0.7173 - val_loss: 0.8426\n",
            "Epoch 58/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9660 - loss: 0.1770\n",
            "Epoch 58: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 25ms/step - accuracy: 0.9659 - loss: 0.1771 - val_accuracy: 0.7202 - val_loss: 0.8558\n",
            "Epoch 59/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9543 - loss: 0.1940\n",
            "Epoch 59: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 25ms/step - accuracy: 0.9543 - loss: 0.1940 - val_accuracy: 0.7135 - val_loss: 0.8762\n",
            "Epoch 60/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9622 - loss: 0.1778\n",
            "Epoch 60: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9622 - loss: 0.1778 - val_accuracy: 0.7106 - val_loss: 0.8831\n",
            "Epoch 61/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9593 - loss: 0.1740\n",
            "Epoch 61: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9593 - loss: 0.1740 - val_accuracy: 0.7192 - val_loss: 0.8835\n",
            "Epoch 62/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9671 - loss: 0.1540\n",
            "Epoch 62: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - accuracy: 0.9671 - loss: 0.1541 - val_accuracy: 0.7221 - val_loss: 0.8729\n",
            "Epoch 63/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9619 - loss: 0.1607\n",
            "Epoch 63: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 27ms/step - accuracy: 0.9619 - loss: 0.1607 - val_accuracy: 0.7115 - val_loss: 0.8941\n",
            "Epoch 64/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9645 - loss: 0.1580\n",
            "Epoch 64: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.9645 - loss: 0.1580 - val_accuracy: 0.7231 - val_loss: 0.8904\n",
            "Epoch 65/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9694 - loss: 0.1420\n",
            "Epoch 65: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 24ms/step - accuracy: 0.9694 - loss: 0.1420 - val_accuracy: 0.7260 - val_loss: 0.8863\n",
            "Epoch 66/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9700 - loss: 0.1409\n",
            "Epoch 66: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.9700 - loss: 0.1409 - val_accuracy: 0.7163 - val_loss: 0.9018\n",
            "Epoch 67/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9739 - loss: 0.1347\n",
            "Epoch 67: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - accuracy: 0.9739 - loss: 0.1346 - val_accuracy: 0.7279 - val_loss: 0.8982\n",
            "Epoch 68/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9605 - loss: 0.1574\n",
            "Epoch 68: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.9605 - loss: 0.1574 - val_accuracy: 0.7212 - val_loss: 0.9173\n",
            "Epoch 69/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9748 - loss: 0.1230\n",
            "Epoch 69: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9747 - loss: 0.1230 - val_accuracy: 0.7317 - val_loss: 0.9198\n",
            "Epoch 70/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9727 - loss: 0.1211\n",
            "Epoch 70: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9727 - loss: 0.1211 - val_accuracy: 0.7212 - val_loss: 0.9364\n",
            "Epoch 71/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9732 - loss: 0.1158\n",
            "Epoch 71: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 0.9732 - loss: 0.1159 - val_accuracy: 0.7279 - val_loss: 0.9341\n",
            "Epoch 72/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9656 - loss: 0.1311\n",
            "Epoch 72: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.9656 - loss: 0.1310 - val_accuracy: 0.7106 - val_loss: 0.9667\n",
            "Epoch 73/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9789 - loss: 0.1130\n",
            "Epoch 73: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - accuracy: 0.9789 - loss: 0.1130 - val_accuracy: 0.7106 - val_loss: 1.0056\n",
            "Epoch 74/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9823 - loss: 0.0966\n",
            "Epoch 74: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9823 - loss: 0.0967 - val_accuracy: 0.7221 - val_loss: 0.9558\n",
            "Epoch 75/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9760 - loss: 0.1064\n",
            "Epoch 75: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 25ms/step - accuracy: 0.9760 - loss: 0.1064 - val_accuracy: 0.7240 - val_loss: 0.9743\n",
            "Epoch 76/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9820 - loss: 0.0890\n",
            "Epoch 76: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.9820 - loss: 0.0891 - val_accuracy: 0.7337 - val_loss: 0.9627\n",
            "Epoch 77/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9844 - loss: 0.0996\n",
            "Epoch 77: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 0.9843 - loss: 0.0996 - val_accuracy: 0.7202 - val_loss: 0.9890\n",
            "Epoch 78/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9846 - loss: 0.0962\n",
            "Epoch 78: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.9846 - loss: 0.0961 - val_accuracy: 0.7240 - val_loss: 0.9859\n",
            "Epoch 79/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9905 - loss: 0.0798\n",
            "Epoch 79: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9905 - loss: 0.0798 - val_accuracy: 0.7154 - val_loss: 1.0128\n",
            "Epoch 80/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9800 - loss: 0.0942\n",
            "Epoch 80: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.9800 - loss: 0.0942 - val_accuracy: 0.7173 - val_loss: 1.0225\n",
            "Epoch 81/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9846 - loss: 0.0847\n",
            "Epoch 81: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9846 - loss: 0.0847 - val_accuracy: 0.7308 - val_loss: 1.0081\n",
            "Epoch 82/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9867 - loss: 0.0779\n",
            "Epoch 82: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.9867 - loss: 0.0779 - val_accuracy: 0.7212 - val_loss: 1.0117\n",
            "Epoch 83/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9856 - loss: 0.0740\n",
            "Epoch 83: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.9856 - loss: 0.0740 - val_accuracy: 0.7250 - val_loss: 1.0128\n",
            "Epoch 84/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9860 - loss: 0.0787\n",
            "Epoch 84: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 24ms/step - accuracy: 0.9860 - loss: 0.0787 - val_accuracy: 0.7154 - val_loss: 1.0502\n",
            "Epoch 85/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9885 - loss: 0.0846\n",
            "Epoch 85: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 0.9885 - loss: 0.0844 - val_accuracy: 0.7173 - val_loss: 1.0564\n",
            "Epoch 86/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9888 - loss: 0.0771\n",
            "Epoch 86: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.9888 - loss: 0.0770 - val_accuracy: 0.7144 - val_loss: 1.0687\n",
            "Epoch 87/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9905 - loss: 0.0655\n",
            "Epoch 87: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.9905 - loss: 0.0655 - val_accuracy: 0.7067 - val_loss: 1.1047\n",
            "Epoch 88/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9880 - loss: 0.0746\n",
            "Epoch 88: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9880 - loss: 0.0746 - val_accuracy: 0.7183 - val_loss: 1.0650\n",
            "Epoch 89/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9886 - loss: 0.0645\n",
            "Epoch 89: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 25ms/step - accuracy: 0.9886 - loss: 0.0646 - val_accuracy: 0.7250 - val_loss: 1.0617\n",
            "Epoch 90/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9909 - loss: 0.0571\n",
            "Epoch 90: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - accuracy: 0.9909 - loss: 0.0571 - val_accuracy: 0.7260 - val_loss: 1.0635\n",
            "Epoch 91/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9874 - loss: 0.0621\n",
            "Epoch 91: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 25ms/step - accuracy: 0.9874 - loss: 0.0621 - val_accuracy: 0.7221 - val_loss: 1.0782\n",
            "Epoch 92/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9925 - loss: 0.0525\n",
            "Epoch 92: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.9925 - loss: 0.0525 - val_accuracy: 0.7212 - val_loss: 1.1223\n",
            "Epoch 93/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9924 - loss: 0.0538\n",
            "Epoch 93: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 23ms/step - accuracy: 0.9923 - loss: 0.0539 - val_accuracy: 0.7173 - val_loss: 1.0925\n",
            "Epoch 94/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9899 - loss: 0.0605\n",
            "Epoch 94: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9899 - loss: 0.0605 - val_accuracy: 0.7221 - val_loss: 1.1234\n",
            "Epoch 95/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9942 - loss: 0.0490\n",
            "Epoch 95: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.9942 - loss: 0.0490 - val_accuracy: 0.7240 - val_loss: 1.1002\n",
            "Epoch 96/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9917 - loss: 0.0505\n",
            "Epoch 96: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.9917 - loss: 0.0505 - val_accuracy: 0.7260 - val_loss: 1.1096\n",
            "Epoch 97/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9897 - loss: 0.0556\n",
            "Epoch 97: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.9897 - loss: 0.0556 - val_accuracy: 0.7212 - val_loss: 1.1253\n",
            "Epoch 98/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9930 - loss: 0.0500\n",
            "Epoch 98: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.9930 - loss: 0.0500 - val_accuracy: 0.7250 - val_loss: 1.1207\n",
            "Epoch 99/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9915 - loss: 0.0496\n",
            "Epoch 99: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.9915 - loss: 0.0496 - val_accuracy: 0.7308 - val_loss: 1.1348\n",
            "Epoch 100/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9950 - loss: 0.0442\n",
            "Epoch 100: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9950 - loss: 0.0443 - val_accuracy: 0.7173 - val_loss: 1.1348\n",
            "Epoch 101/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9899 - loss: 0.0531\n",
            "Epoch 101: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 24ms/step - accuracy: 0.9900 - loss: 0.0531 - val_accuracy: 0.7288 - val_loss: 1.1407\n",
            "Epoch 102/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9954 - loss: 0.0399\n",
            "Epoch 102: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.9954 - loss: 0.0400 - val_accuracy: 0.7212 - val_loss: 1.1563\n",
            "Epoch 103/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9944 - loss: 0.0456\n",
            "Epoch 103: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 0.9944 - loss: 0.0456 - val_accuracy: 0.7202 - val_loss: 1.1696\n",
            "Epoch 104/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9947 - loss: 0.0388\n",
            "Epoch 104: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9947 - loss: 0.0389 - val_accuracy: 0.7240 - val_loss: 1.1721\n",
            "Epoch 105/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9960 - loss: 0.0373\n",
            "Epoch 105: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.9960 - loss: 0.0373 - val_accuracy: 0.7240 - val_loss: 1.1638\n",
            "Epoch 106/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9955 - loss: 0.0413\n",
            "Epoch 106: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.9955 - loss: 0.0413 - val_accuracy: 0.7337 - val_loss: 1.1628\n",
            "Epoch 107/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9934 - loss: 0.0364\n",
            "Epoch 107: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9934 - loss: 0.0364 - val_accuracy: 0.7260 - val_loss: 1.1684\n",
            "Epoch 108/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9930 - loss: 0.0419\n",
            "Epoch 108: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 27ms/step - accuracy: 0.9930 - loss: 0.0419 - val_accuracy: 0.7231 - val_loss: 1.1900\n",
            "Epoch 109/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9959 - loss: 0.0358\n",
            "Epoch 109: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 24ms/step - accuracy: 0.9959 - loss: 0.0358 - val_accuracy: 0.7260 - val_loss: 1.2024\n",
            "Epoch 110/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9941 - loss: 0.0424\n",
            "Epoch 110: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.9942 - loss: 0.0424 - val_accuracy: 0.7317 - val_loss: 1.2070\n",
            "Epoch 111/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9951 - loss: 0.0341\n",
            "Epoch 111: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9951 - loss: 0.0341 - val_accuracy: 0.7308 - val_loss: 1.1958\n",
            "Epoch 112/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9936 - loss: 0.0366\n",
            "Epoch 112: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - accuracy: 0.9936 - loss: 0.0366 - val_accuracy: 0.7279 - val_loss: 1.2102\n",
            "Epoch 113/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9952 - loss: 0.0340\n",
            "Epoch 113: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.9952 - loss: 0.0340 - val_accuracy: 0.7260 - val_loss: 1.2361\n",
            "Epoch 114/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9959 - loss: 0.0329\n",
            "Epoch 114: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.9959 - loss: 0.0329 - val_accuracy: 0.7250 - val_loss: 1.2419\n",
            "Epoch 115/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9968 - loss: 0.0319\n",
            "Epoch 115: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9968 - loss: 0.0319 - val_accuracy: 0.7250 - val_loss: 1.2395\n",
            "Epoch 116/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9963 - loss: 0.0308\n",
            "Epoch 116: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - accuracy: 0.9963 - loss: 0.0308 - val_accuracy: 0.7317 - val_loss: 1.2423\n",
            "Epoch 117/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9964 - loss: 0.0291\n",
            "Epoch 117: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 28ms/step - accuracy: 0.9964 - loss: 0.0291 - val_accuracy: 0.7269 - val_loss: 1.2643\n",
            "Epoch 118/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9957 - loss: 0.0307\n",
            "Epoch 118: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 24ms/step - accuracy: 0.9957 - loss: 0.0307 - val_accuracy: 0.7250 - val_loss: 1.2932\n",
            "Epoch 119/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9933 - loss: 0.0402\n",
            "Epoch 119: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9933 - loss: 0.0402 - val_accuracy: 0.7221 - val_loss: 1.2981\n",
            "Epoch 120/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9956 - loss: 0.0339\n",
            "Epoch 120: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - accuracy: 0.9956 - loss: 0.0339 - val_accuracy: 0.7327 - val_loss: 1.2794\n",
            "Epoch 121/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9972 - loss: 0.0240\n",
            "Epoch 121: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.9972 - loss: 0.0240 - val_accuracy: 0.7308 - val_loss: 1.2736\n",
            "Epoch 122/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9947 - loss: 0.0356\n",
            "Epoch 122: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9947 - loss: 0.0356 - val_accuracy: 0.7317 - val_loss: 1.2977\n",
            "Epoch 123/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9966 - loss: 0.0266\n",
            "Epoch 123: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - accuracy: 0.9966 - loss: 0.0267 - val_accuracy: 0.7308 - val_loss: 1.3307\n",
            "Epoch 124/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9980 - loss: 0.0254\n",
            "Epoch 124: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9980 - loss: 0.0254 - val_accuracy: 0.7346 - val_loss: 1.3072\n",
            "Epoch 125/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9978 - loss: 0.0215\n",
            "Epoch 125: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9978 - loss: 0.0215 - val_accuracy: 0.7298 - val_loss: 1.3445\n",
            "Epoch 126/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9975 - loss: 0.0234\n",
            "Epoch 126: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9975 - loss: 0.0235 - val_accuracy: 0.7288 - val_loss: 1.3293\n",
            "Epoch 127/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9957 - loss: 0.0283\n",
            "Epoch 127: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9957 - loss: 0.0283 - val_accuracy: 0.7317 - val_loss: 1.3326\n",
            "Epoch 128/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9937 - loss: 0.0319\n",
            "Epoch 128: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 27ms/step - accuracy: 0.9937 - loss: 0.0318 - val_accuracy: 0.7327 - val_loss: 1.3537\n",
            "Epoch 129/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9979 - loss: 0.0228\n",
            "Epoch 129: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 24ms/step - accuracy: 0.9978 - loss: 0.0229 - val_accuracy: 0.7337 - val_loss: 1.3467\n",
            "Epoch 130/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9966 - loss: 0.0233\n",
            "Epoch 130: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9966 - loss: 0.0233 - val_accuracy: 0.7317 - val_loss: 1.3523\n",
            "Epoch 131/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9972 - loss: 0.0229\n",
            "Epoch 131: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.9972 - loss: 0.0229 - val_accuracy: 0.7365 - val_loss: 1.3945\n",
            "Epoch 132/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9974 - loss: 0.0243\n",
            "Epoch 132: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.9974 - loss: 0.0243 - val_accuracy: 0.7337 - val_loss: 1.3735\n",
            "Epoch 133/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9957 - loss: 0.0231\n",
            "Epoch 133: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.9957 - loss: 0.0231 - val_accuracy: 0.7365 - val_loss: 1.3673\n",
            "Epoch 134/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9944 - loss: 0.0273\n",
            "Epoch 134: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.9944 - loss: 0.0273 - val_accuracy: 0.7433 - val_loss: 1.3941\n",
            "Epoch 135/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9977 - loss: 0.0193\n",
            "Epoch 135: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.9977 - loss: 0.0193 - val_accuracy: 0.7317 - val_loss: 1.3892\n",
            "Epoch 136/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9956 - loss: 0.0268\n",
            "Epoch 136: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9956 - loss: 0.0268 - val_accuracy: 0.7308 - val_loss: 1.4073\n",
            "Epoch 137/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9962 - loss: 0.0201\n",
            "Epoch 137: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9962 - loss: 0.0201 - val_accuracy: 0.7385 - val_loss: 1.4134\n",
            "Epoch 138/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9960 - loss: 0.0224\n",
            "Epoch 138: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9960 - loss: 0.0223 - val_accuracy: 0.7231 - val_loss: 1.4373\n",
            "Epoch 139/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9982 - loss: 0.0211\n",
            "Epoch 139: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.9982 - loss: 0.0211 - val_accuracy: 0.7356 - val_loss: 1.4507\n",
            "Epoch 140/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9982 - loss: 0.0169\n",
            "Epoch 140: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9982 - loss: 0.0169 - val_accuracy: 0.7029 - val_loss: 1.5026\n",
            "Epoch 141/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9978 - loss: 0.0196\n",
            "Epoch 141: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9978 - loss: 0.0196 - val_accuracy: 0.7375 - val_loss: 1.4611\n",
            "Epoch 142/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9965 - loss: 0.0202\n",
            "Epoch 142: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.9965 - loss: 0.0201 - val_accuracy: 0.7308 - val_loss: 1.4588\n",
            "Epoch 143/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9980 - loss: 0.0174\n",
            "Epoch 143: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 25ms/step - accuracy: 0.9980 - loss: 0.0174 - val_accuracy: 0.7250 - val_loss: 1.5098\n",
            "Epoch 144/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9962 - loss: 0.0242\n",
            "Epoch 144: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - accuracy: 0.9962 - loss: 0.0242 - val_accuracy: 0.7346 - val_loss: 1.4674\n",
            "Epoch 145/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9981 - loss: 0.0184\n",
            "Epoch 145: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - accuracy: 0.9981 - loss: 0.0184 - val_accuracy: 0.7346 - val_loss: 1.4522\n",
            "Epoch 146/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9982 - loss: 0.0161\n",
            "Epoch 146: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.9982 - loss: 0.0162 - val_accuracy: 0.7269 - val_loss: 1.5232\n",
            "Epoch 147/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9962 - loss: 0.0175\n",
            "Epoch 147: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9962 - loss: 0.0175 - val_accuracy: 0.7173 - val_loss: 1.4735\n",
            "Epoch 148/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9986 - loss: 0.0157\n",
            "Epoch 148: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 28ms/step - accuracy: 0.9986 - loss: 0.0157 - val_accuracy: 0.7279 - val_loss: 1.5375\n",
            "Epoch 149/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9965 - loss: 0.0165\n",
            "Epoch 149: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 24ms/step - accuracy: 0.9965 - loss: 0.0165 - val_accuracy: 0.7337 - val_loss: 1.5362\n",
            "Epoch 150/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9953 - loss: 0.0194\n",
            "Epoch 150: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.9953 - loss: 0.0194 - val_accuracy: 0.7337 - val_loss: 1.4916\n",
            "Epoch 151/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9987 - loss: 0.0149\n",
            "Epoch 151: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.9987 - loss: 0.0149 - val_accuracy: 0.7221 - val_loss: 1.4962\n",
            "Epoch 152/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9958 - loss: 0.0201\n",
            "Epoch 152: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9958 - loss: 0.0201 - val_accuracy: 0.7288 - val_loss: 1.4991\n",
            "Epoch 153/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9981 - loss: 0.0138\n",
            "Epoch 153: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 28ms/step - accuracy: 0.9981 - loss: 0.0138 - val_accuracy: 0.7279 - val_loss: 1.5307\n",
            "Epoch 154/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9993 - loss: 0.0119\n",
            "Epoch 154: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 25ms/step - accuracy: 0.9993 - loss: 0.0120 - val_accuracy: 0.7337 - val_loss: 1.5005\n",
            "Epoch 155/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9986 - loss: 0.0128\n",
            "Epoch 155: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.9986 - loss: 0.0128 - val_accuracy: 0.7269 - val_loss: 1.5095\n",
            "Epoch 156/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9963 - loss: 0.0206\n",
            "Epoch 156: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9963 - loss: 0.0206 - val_accuracy: 0.7375 - val_loss: 1.5353\n",
            "Epoch 157/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9978 - loss: 0.0189\n",
            "Epoch 157: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - accuracy: 0.9978 - loss: 0.0189 - val_accuracy: 0.7240 - val_loss: 1.5259\n",
            "Epoch 158/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9988 - loss: 0.0128\n",
            "Epoch 158: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9988 - loss: 0.0128 - val_accuracy: 0.7279 - val_loss: 1.5461\n",
            "Epoch 159/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9988 - loss: 0.0134\n",
            "Epoch 159: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9988 - loss: 0.0134 - val_accuracy: 0.7327 - val_loss: 1.5338\n",
            "Epoch 160/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9998 - loss: 0.0108\n",
            "Epoch 160: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9998 - loss: 0.0108 - val_accuracy: 0.7250 - val_loss: 1.5471\n",
            "Epoch 161/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9975 - loss: 0.0162\n",
            "Epoch 161: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.9975 - loss: 0.0162 - val_accuracy: 0.7327 - val_loss: 1.5510\n",
            "Epoch 162/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9989 - loss: 0.0115\n",
            "Epoch 162: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 27ms/step - accuracy: 0.9989 - loss: 0.0115 - val_accuracy: 0.7173 - val_loss: 1.5796\n",
            "Epoch 163/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9959 - loss: 0.0215\n",
            "Epoch 163: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - accuracy: 0.9960 - loss: 0.0215 - val_accuracy: 0.7260 - val_loss: 1.6129\n",
            "Epoch 164/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9984 - loss: 0.0126\n",
            "Epoch 164: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 28ms/step - accuracy: 0.9984 - loss: 0.0126 - val_accuracy: 0.7250 - val_loss: 1.5468\n",
            "Epoch 165/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9996 - loss: 0.0130\n",
            "Epoch 165: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 24ms/step - accuracy: 0.9996 - loss: 0.0130 - val_accuracy: 0.7269 - val_loss: 1.5979\n",
            "Epoch 166/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9978 - loss: 0.0136\n",
            "Epoch 166: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.9978 - loss: 0.0136 - val_accuracy: 0.7212 - val_loss: 1.6259\n",
            "Epoch 167/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9994 - loss: 0.0101\n",
            "Epoch 167: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9994 - loss: 0.0101 - val_accuracy: 0.7231 - val_loss: 1.6015\n",
            "Epoch 168/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9983 - loss: 0.0120\n",
            "Epoch 168: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9983 - loss: 0.0120 - val_accuracy: 0.7260 - val_loss: 1.6177\n",
            "Epoch 169/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9975 - loss: 0.0159\n",
            "Epoch 169: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9975 - loss: 0.0159 - val_accuracy: 0.7019 - val_loss: 1.6035\n",
            "Epoch 170/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9976 - loss: 0.0125\n",
            "Epoch 170: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9976 - loss: 0.0125 - val_accuracy: 0.7231 - val_loss: 1.6013\n",
            "Epoch 171/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9974 - loss: 0.0134\n",
            "Epoch 171: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 25ms/step - accuracy: 0.9974 - loss: 0.0134 - val_accuracy: 0.7058 - val_loss: 1.6869\n",
            "Epoch 172/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9963 - loss: 0.0138\n",
            "Epoch 172: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.9964 - loss: 0.0138 - val_accuracy: 0.7250 - val_loss: 1.6179\n",
            "Epoch 173/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9981 - loss: 0.0131\n",
            "Epoch 173: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.9981 - loss: 0.0131 - val_accuracy: 0.7279 - val_loss: 1.6400\n",
            "Epoch 174/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9976 - loss: 0.0145\n",
            "Epoch 174: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9976 - loss: 0.0145 - val_accuracy: 0.7308 - val_loss: 1.6221\n",
            "Epoch 175/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9988 - loss: 0.0103\n",
            "Epoch 175: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 23ms/step - accuracy: 0.9988 - loss: 0.0103 - val_accuracy: 0.7279 - val_loss: 1.6449\n",
            "Epoch 176/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9984 - loss: 0.0121\n",
            "Epoch 176: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9984 - loss: 0.0121 - val_accuracy: 0.7269 - val_loss: 1.6311\n",
            "Epoch 177/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9978 - loss: 0.0103\n",
            "Epoch 177: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 27ms/step - accuracy: 0.9978 - loss: 0.0103 - val_accuracy: 0.7288 - val_loss: 1.6323\n",
            "Epoch 178/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9983 - loss: 0.0121\n",
            "Epoch 178: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9983 - loss: 0.0121 - val_accuracy: 0.7298 - val_loss: 1.6184\n",
            "Epoch 179/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9989 - loss: 0.0108\n",
            "Epoch 179: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 25ms/step - accuracy: 0.9989 - loss: 0.0108 - val_accuracy: 0.7212 - val_loss: 1.6152\n",
            "Epoch 180/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9973 - loss: 0.0161\n",
            "Epoch 180: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 0.9973 - loss: 0.0161 - val_accuracy: 0.7288 - val_loss: 1.6517\n",
            "Epoch 181/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9980 - loss: 0.0117\n",
            "Epoch 181: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9980 - loss: 0.0117 - val_accuracy: 0.7135 - val_loss: 1.6631\n",
            "Epoch 182/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9990 - loss: 0.0108\n",
            "Epoch 182: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9990 - loss: 0.0108 - val_accuracy: 0.7106 - val_loss: 1.8324\n",
            "Epoch 183/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9973 - loss: 0.0129\n",
            "Epoch 183: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9973 - loss: 0.0129 - val_accuracy: 0.7288 - val_loss: 1.6590\n",
            "Epoch 184/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9999 - loss: 0.0074\n",
            "Epoch 184: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 25ms/step - accuracy: 0.9999 - loss: 0.0074 - val_accuracy: 0.7240 - val_loss: 1.6563\n",
            "Epoch 185/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9993 - loss: 0.0093\n",
            "Epoch 185: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9993 - loss: 0.0093 - val_accuracy: 0.7231 - val_loss: 1.6585\n",
            "Epoch 186/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9992 - loss: 0.0086\n",
            "Epoch 186: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9992 - loss: 0.0086 - val_accuracy: 0.7269 - val_loss: 1.7003\n",
            "Epoch 187/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9986 - loss: 0.0113\n",
            "Epoch 187: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9986 - loss: 0.0113 - val_accuracy: 0.6885 - val_loss: 1.9131\n",
            "Epoch 188/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9992 - loss: 0.0094\n",
            "Epoch 188: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9992 - loss: 0.0094 - val_accuracy: 0.7183 - val_loss: 1.6996\n",
            "Epoch 189/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9983 - loss: 0.0091\n",
            "Epoch 189: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.9983 - loss: 0.0091 - val_accuracy: 0.7240 - val_loss: 1.7016\n",
            "Epoch 190/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9977 - loss: 0.0123\n",
            "Epoch 190: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9977 - loss: 0.0123 - val_accuracy: 0.7192 - val_loss: 1.7029\n",
            "Epoch 191/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9989 - loss: 0.0098\n",
            "Epoch 191: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 25ms/step - accuracy: 0.9989 - loss: 0.0098 - val_accuracy: 0.7154 - val_loss: 1.7514\n",
            "Epoch 192/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9970 - loss: 0.0126\n",
            "Epoch 192: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9970 - loss: 0.0126 - val_accuracy: 0.7231 - val_loss: 1.7149\n",
            "Epoch 193/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9990 - loss: 0.0086\n",
            "Epoch 193: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9990 - loss: 0.0086 - val_accuracy: 0.7135 - val_loss: 1.7146\n",
            "Epoch 194/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9994 - loss: 0.0090\n",
            "Epoch 194: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 24ms/step - accuracy: 0.9994 - loss: 0.0090 - val_accuracy: 0.7125 - val_loss: 1.7278\n",
            "Epoch 195/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9995 - loss: 0.0073\n",
            "Epoch 195: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9995 - loss: 0.0073 - val_accuracy: 0.7173 - val_loss: 1.7517\n",
            "Epoch 196/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9987 - loss: 0.0102\n",
            "Epoch 196: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9987 - loss: 0.0102 - val_accuracy: 0.7202 - val_loss: 1.7265\n",
            "Epoch 197/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9987 - loss: 0.0087\n",
            "Epoch 197: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9987 - loss: 0.0087 - val_accuracy: 0.7173 - val_loss: 1.7694\n",
            "Epoch 198/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9989 - loss: 0.0079\n",
            "Epoch 198: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9989 - loss: 0.0079 - val_accuracy: 0.7221 - val_loss: 1.7545\n",
            "Epoch 199/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9988 - loss: 0.0081\n",
            "Epoch 199: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9988 - loss: 0.0081 - val_accuracy: 0.7240 - val_loss: 1.7629\n",
            "Epoch 200/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9983 - loss: 0.0105\n",
            "Epoch 200: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 0.9983 - loss: 0.0105 - val_accuracy: 0.7279 - val_loss: 1.7774\n",
            "Epoch 201/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9997 - loss: 0.0067\n",
            "Epoch 201: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 25ms/step - accuracy: 0.9997 - loss: 0.0067 - val_accuracy: 0.7192 - val_loss: 1.7708\n",
            "Epoch 202/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9985 - loss: 0.0094\n",
            "Epoch 202: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.9985 - loss: 0.0094 - val_accuracy: 0.7269 - val_loss: 1.7894\n",
            "Epoch 203/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9996 - loss: 0.0078\n",
            "Epoch 203: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9996 - loss: 0.0078 - val_accuracy: 0.7144 - val_loss: 1.7328\n",
            "Epoch 204/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9999 - loss: 0.0060\n",
            "Epoch 204: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 27ms/step - accuracy: 0.9999 - loss: 0.0060 - val_accuracy: 0.7221 - val_loss: 1.8810\n",
            "Epoch 205/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9991 - loss: 0.0067\n",
            "Epoch 205: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9991 - loss: 0.0067 - val_accuracy: 0.7192 - val_loss: 1.7597\n",
            "Epoch 206/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9994 - loss: 0.0070\n",
            "Epoch 206: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9994 - loss: 0.0070 - val_accuracy: 0.7183 - val_loss: 1.8466\n",
            "Epoch 207/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9995 - loss: 0.0069\n",
            "Epoch 207: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9995 - loss: 0.0069 - val_accuracy: 0.7231 - val_loss: 1.8072\n",
            "Epoch 208/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9997 - loss: 0.0057\n",
            "Epoch 208: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 25ms/step - accuracy: 0.9997 - loss: 0.0057 - val_accuracy: 0.7192 - val_loss: 1.7957\n",
            "Epoch 209/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9977 - loss: 0.0108\n",
            "Epoch 209: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9977 - loss: 0.0108 - val_accuracy: 0.7202 - val_loss: 1.8025\n",
            "Epoch 210/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0058\n",
            "Epoch 210: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0058 - val_accuracy: 0.7221 - val_loss: 1.8600\n",
            "Epoch 211/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0061\n",
            "Epoch 211: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0061 - val_accuracy: 0.7038 - val_loss: 1.8993\n",
            "Epoch 212/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9999 - loss: 0.0069\n",
            "Epoch 212: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9999 - loss: 0.0069 - val_accuracy: 0.7135 - val_loss: 1.8599\n",
            "Epoch 213/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9996 - loss: 0.0071\n",
            "Epoch 213: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9996 - loss: 0.0071 - val_accuracy: 0.7192 - val_loss: 1.9152\n",
            "Epoch 214/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9991 - loss: 0.0073\n",
            "Epoch 214: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.9991 - loss: 0.0073 - val_accuracy: 0.7144 - val_loss: 1.8744\n",
            "Epoch 215/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9981 - loss: 0.0081\n",
            "Epoch 215: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9981 - loss: 0.0080 - val_accuracy: 0.7250 - val_loss: 1.8401\n",
            "Epoch 216/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9995 - loss: 0.0060\n",
            "Epoch 216: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 0.9995 - loss: 0.0060 - val_accuracy: 0.7192 - val_loss: 1.7970\n",
            "Epoch 217/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9988 - loss: 0.0078\n",
            "Epoch 217: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 27ms/step - accuracy: 0.9988 - loss: 0.0078 - val_accuracy: 0.7317 - val_loss: 1.8407\n",
            "Epoch 218/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9982 - loss: 0.0104\n",
            "Epoch 218: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - accuracy: 0.9982 - loss: 0.0104 - val_accuracy: 0.7250 - val_loss: 1.8444\n",
            "Epoch 219/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9994 - loss: 0.0061\n",
            "Epoch 219: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - accuracy: 0.9994 - loss: 0.0061 - val_accuracy: 0.7298 - val_loss: 1.8499\n",
            "Epoch 220/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9998 - loss: 0.0070\n",
            "Epoch 220: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.9998 - loss: 0.0070 - val_accuracy: 0.7202 - val_loss: 1.8554\n",
            "Epoch 221/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9956 - loss: 0.0138\n",
            "Epoch 221: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 25ms/step - accuracy: 0.9956 - loss: 0.0138 - val_accuracy: 0.7221 - val_loss: 1.8757\n",
            "Epoch 222/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9987 - loss: 0.0069\n",
            "Epoch 222: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.9988 - loss: 0.0069 - val_accuracy: 0.7288 - val_loss: 1.8634\n",
            "Epoch 223/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0051\n",
            "Epoch 223: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 0.7288 - val_loss: 1.8462\n",
            "Epoch 224/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0044\n",
            "Epoch 224: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 0.7250 - val_loss: 1.9143\n",
            "Epoch 225/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9985 - loss: 0.0087\n",
            "Epoch 225: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 25ms/step - accuracy: 0.9985 - loss: 0.0087 - val_accuracy: 0.7212 - val_loss: 1.8852\n",
            "Epoch 226/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0050\n",
            "Epoch 226: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 0.7144 - val_loss: 1.9175\n",
            "Epoch 227/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9994 - loss: 0.0068\n",
            "Epoch 227: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - accuracy: 0.9994 - loss: 0.0068 - val_accuracy: 0.7279 - val_loss: 1.9039\n",
            "Epoch 228/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9991 - loss: 0.0054\n",
            "Epoch 228: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 0.9991 - loss: 0.0054 - val_accuracy: 0.7269 - val_loss: 1.8986\n",
            "Epoch 229/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9999 - loss: 0.0058\n",
            "Epoch 229: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9999 - loss: 0.0058 - val_accuracy: 0.7221 - val_loss: 1.8992\n",
            "Epoch 230/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9989 - loss: 0.0072\n",
            "Epoch 230: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 0.9989 - loss: 0.0072 - val_accuracy: 0.7067 - val_loss: 2.1038\n",
            "Epoch 231/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9976 - loss: 0.0081\n",
            "Epoch 231: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9976 - loss: 0.0081 - val_accuracy: 0.7250 - val_loss: 1.8893\n",
            "Epoch 232/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9990 - loss: 0.0067\n",
            "Epoch 232: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9990 - loss: 0.0067 - val_accuracy: 0.6990 - val_loss: 2.0049\n",
            "Epoch 233/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9989 - loss: 0.0109\n",
            "Epoch 233: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9989 - loss: 0.0108 - val_accuracy: 0.7269 - val_loss: 1.9163\n",
            "Epoch 234/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9999 - loss: 0.0051\n",
            "Epoch 234: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - accuracy: 0.9999 - loss: 0.0051 - val_accuracy: 0.7173 - val_loss: 1.8914\n",
            "Epoch 235/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9998 - loss: 0.0042\n",
            "Epoch 235: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 25ms/step - accuracy: 0.9998 - loss: 0.0042 - val_accuracy: 0.6894 - val_loss: 2.2095\n",
            "Epoch 236/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9997 - loss: 0.0056\n",
            "Epoch 236: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.9997 - loss: 0.0056 - val_accuracy: 0.7192 - val_loss: 1.9138\n",
            "Epoch 237/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9996 - loss: 0.0051\n",
            "Epoch 237: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 25ms/step - accuracy: 0.9995 - loss: 0.0051 - val_accuracy: 0.7125 - val_loss: 1.8662\n",
            "Epoch 238/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9968 - loss: 0.0118\n",
            "Epoch 238: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9968 - loss: 0.0117 - val_accuracy: 0.7221 - val_loss: 1.9038\n",
            "Epoch 239/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9993 - loss: 0.0049\n",
            "Epoch 239: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - accuracy: 0.9993 - loss: 0.0049 - val_accuracy: 0.7019 - val_loss: 2.0126\n",
            "Epoch 240/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9982 - loss: 0.0076\n",
            "Epoch 240: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.9982 - loss: 0.0076 - val_accuracy: 0.7240 - val_loss: 1.9148\n",
            "Epoch 241/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9985 - loss: 0.0075\n",
            "Epoch 241: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 25ms/step - accuracy: 0.9985 - loss: 0.0075 - val_accuracy: 0.7260 - val_loss: 1.9499\n",
            "Epoch 242/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9998 - loss: 0.0050\n",
            "Epoch 242: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9998 - loss: 0.0050 - val_accuracy: 0.7240 - val_loss: 1.9302\n",
            "Epoch 243/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9998 - loss: 0.0044\n",
            "Epoch 243: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - accuracy: 0.9998 - loss: 0.0044 - val_accuracy: 0.7231 - val_loss: 1.9370\n",
            "Epoch 244/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9993 - loss: 0.0041\n",
            "Epoch 244: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 0.9993 - loss: 0.0041 - val_accuracy: 0.7240 - val_loss: 1.9426\n",
            "Epoch 245/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9997 - loss: 0.0043\n",
            "Epoch 245: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.9997 - loss: 0.0043 - val_accuracy: 0.7183 - val_loss: 1.9052\n",
            "Epoch 246/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0031\n",
            "Epoch 246: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.7192 - val_loss: 1.9505\n",
            "Epoch 247/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9996 - loss: 0.0053\n",
            "Epoch 247: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 25ms/step - accuracy: 0.9996 - loss: 0.0053 - val_accuracy: 0.7183 - val_loss: 1.9362\n",
            "Epoch 248/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9984 - loss: 0.0068\n",
            "Epoch 248: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9984 - loss: 0.0067 - val_accuracy: 0.7212 - val_loss: 1.9571\n",
            "Epoch 249/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9979 - loss: 0.0094\n",
            "Epoch 249: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9979 - loss: 0.0094 - val_accuracy: 0.7038 - val_loss: 1.9599\n",
            "Epoch 250/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9985 - loss: 0.0074\n",
            "Epoch 250: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9985 - loss: 0.0074 - val_accuracy: 0.7115 - val_loss: 1.9480\n",
            "Epoch 251/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0054\n",
            "Epoch 251: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0054 - val_accuracy: 0.7231 - val_loss: 1.9622\n",
            "Epoch 252/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9980 - loss: 0.0070\n",
            "Epoch 252: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9980 - loss: 0.0070 - val_accuracy: 0.7240 - val_loss: 1.9792\n",
            "Epoch 253/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9985 - loss: 0.0076\n",
            "Epoch 253: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.9985 - loss: 0.0076 - val_accuracy: 0.7202 - val_loss: 1.9970\n",
            "Epoch 254/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9999 - loss: 0.0031\n",
            "Epoch 254: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - accuracy: 0.9999 - loss: 0.0031 - val_accuracy: 0.7202 - val_loss: 1.9767\n",
            "Epoch 255/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9996 - loss: 0.0045\n",
            "Epoch 255: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9996 - loss: 0.0045 - val_accuracy: 0.7231 - val_loss: 1.9622\n",
            "Epoch 256/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9981 - loss: 0.0074\n",
            "Epoch 256: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9981 - loss: 0.0074 - val_accuracy: 0.7212 - val_loss: 1.9659\n",
            "Epoch 257/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0036\n",
            "Epoch 257: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.7221 - val_loss: 1.9672\n",
            "Epoch 258/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9998 - loss: 0.0051\n",
            "Epoch 258: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9998 - loss: 0.0051 - val_accuracy: 0.7231 - val_loss: 1.9917\n",
            "Epoch 259/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9991 - loss: 0.0056\n",
            "Epoch 259: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9991 - loss: 0.0056 - val_accuracy: 0.7202 - val_loss: 2.0106\n",
            "Epoch 260/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0037\n",
            "Epoch 260: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0037 - val_accuracy: 0.7173 - val_loss: 1.9794\n",
            "Epoch 261/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9998 - loss: 0.0045\n",
            "Epoch 261: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 25ms/step - accuracy: 0.9998 - loss: 0.0046 - val_accuracy: 0.7202 - val_loss: 2.0415\n",
            "Epoch 262/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9999 - loss: 0.0036\n",
            "Epoch 262: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9999 - loss: 0.0036 - val_accuracy: 0.7231 - val_loss: 2.0092\n",
            "Epoch 263/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9991 - loss: 0.0056\n",
            "Epoch 263: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 27ms/step - accuracy: 0.9991 - loss: 0.0056 - val_accuracy: 0.7163 - val_loss: 2.1183\n",
            "Epoch 264/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9983 - loss: 0.0081\n",
            "Epoch 264: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9983 - loss: 0.0081 - val_accuracy: 0.7221 - val_loss: 2.0063\n",
            "Epoch 265/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9993 - loss: 0.0068\n",
            "Epoch 265: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 27ms/step - accuracy: 0.9993 - loss: 0.0068 - val_accuracy: 0.7202 - val_loss: 2.0218\n",
            "Epoch 266/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9992 - loss: 0.0048\n",
            "Epoch 266: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - accuracy: 0.9992 - loss: 0.0048 - val_accuracy: 0.7192 - val_loss: 2.0519\n",
            "Epoch 267/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9996 - loss: 0.0039\n",
            "Epoch 267: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - accuracy: 0.9996 - loss: 0.0039 - val_accuracy: 0.7269 - val_loss: 1.9987\n",
            "Epoch 268/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9997 - loss: 0.0035\n",
            "Epoch 268: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 25ms/step - accuracy: 0.9997 - loss: 0.0035 - val_accuracy: 0.7144 - val_loss: 2.0639\n",
            "Epoch 269/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9988 - loss: 0.0047\n",
            "Epoch 269: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9988 - loss: 0.0047 - val_accuracy: 0.7163 - val_loss: 2.0137\n",
            "Epoch 270/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9999 - loss: 0.0037\n",
            "Epoch 270: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 0.9999 - loss: 0.0037 - val_accuracy: 0.7240 - val_loss: 2.0240\n",
            "Epoch 271/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0028\n",
            "Epoch 271: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.7231 - val_loss: 2.0454\n",
            "Epoch 272/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9996 - loss: 0.0030\n",
            "Epoch 272: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9996 - loss: 0.0030 - val_accuracy: 0.7000 - val_loss: 2.0638\n",
            "Epoch 273/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9986 - loss: 0.0052\n",
            "Epoch 273: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 0.9986 - loss: 0.0052 - val_accuracy: 0.7288 - val_loss: 2.0369\n",
            "Epoch 274/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9974 - loss: 0.0064\n",
            "Epoch 274: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 25ms/step - accuracy: 0.9974 - loss: 0.0064 - val_accuracy: 0.7067 - val_loss: 2.2204\n",
            "Epoch 275/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9997 - loss: 0.0050\n",
            "Epoch 275: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9997 - loss: 0.0050 - val_accuracy: 0.7240 - val_loss: 2.0368\n",
            "Epoch 276/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0033\n",
            "Epoch 276: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.7192 - val_loss: 2.0431\n",
            "Epoch 277/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0043\n",
            "Epoch 277: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.7221 - val_loss: 2.0358\n",
            "Epoch 278/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9997 - loss: 0.0046\n",
            "Epoch 278: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9997 - loss: 0.0046 - val_accuracy: 0.7231 - val_loss: 2.0210\n",
            "Epoch 279/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9998 - loss: 0.0040\n",
            "Epoch 279: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 25ms/step - accuracy: 0.9998 - loss: 0.0040 - val_accuracy: 0.7183 - val_loss: 2.0988\n",
            "Epoch 280/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9990 - loss: 0.0045\n",
            "Epoch 280: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 25ms/step - accuracy: 0.9990 - loss: 0.0045 - val_accuracy: 0.7269 - val_loss: 2.0792\n",
            "Epoch 281/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9996 - loss: 0.0057\n",
            "Epoch 281: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - accuracy: 0.9996 - loss: 0.0057 - val_accuracy: 0.7144 - val_loss: 2.1488\n",
            "Epoch 282/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9996 - loss: 0.0051\n",
            "Epoch 282: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9996 - loss: 0.0051 - val_accuracy: 0.7212 - val_loss: 2.1093\n",
            "Epoch 283/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9991 - loss: 0.0042\n",
            "Epoch 283: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9991 - loss: 0.0042 - val_accuracy: 0.7250 - val_loss: 2.0728\n",
            "Epoch 284/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9990 - loss: 0.0048\n",
            "Epoch 284: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 24ms/step - accuracy: 0.9990 - loss: 0.0048 - val_accuracy: 0.7240 - val_loss: 2.1004\n",
            "Epoch 285/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9994 - loss: 0.0050\n",
            "Epoch 285: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - accuracy: 0.9994 - loss: 0.0050 - val_accuracy: 0.7240 - val_loss: 2.0662\n",
            "Epoch 286/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9966 - loss: 0.0092\n",
            "Epoch 286: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9966 - loss: 0.0091 - val_accuracy: 0.7308 - val_loss: 2.1074\n",
            "Epoch 287/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9992 - loss: 0.0058\n",
            "Epoch 287: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 25ms/step - accuracy: 0.9992 - loss: 0.0058 - val_accuracy: 0.7288 - val_loss: 2.0555\n",
            "Epoch 288/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9998 - loss: 0.0036\n",
            "Epoch 288: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.9998 - loss: 0.0036 - val_accuracy: 0.7308 - val_loss: 2.0359\n",
            "Epoch 289/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9996 - loss: 0.0034\n",
            "Epoch 289: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 25ms/step - accuracy: 0.9996 - loss: 0.0034 - val_accuracy: 0.7240 - val_loss: 2.0377\n",
            "Epoch 290/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9985 - loss: 0.0061\n",
            "Epoch 290: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - accuracy: 0.9985 - loss: 0.0061 - val_accuracy: 0.7279 - val_loss: 2.0701\n",
            "Epoch 291/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9999 - loss: 0.0040\n",
            "Epoch 291: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9999 - loss: 0.0040 - val_accuracy: 0.7231 - val_loss: 2.0629\n",
            "Epoch 292/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9996 - loss: 0.0036\n",
            "Epoch 292: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 25ms/step - accuracy: 0.9996 - loss: 0.0036 - val_accuracy: 0.7250 - val_loss: 2.0846\n",
            "Epoch 293/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0037\n",
            "Epoch 293: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0037 - val_accuracy: 0.7231 - val_loss: 2.2650\n",
            "Epoch 294/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0044\n",
            "Epoch 294: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 0.7221 - val_loss: 2.0484\n",
            "Epoch 295/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9994 - loss: 0.0045\n",
            "Epoch 295: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - accuracy: 0.9994 - loss: 0.0045 - val_accuracy: 0.7183 - val_loss: 2.0966\n",
            "Epoch 296/300\n",
            "\u001b[1m258/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9998 - loss: 0.0032\n",
            "Epoch 296: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 26ms/step - accuracy: 0.9998 - loss: 0.0032 - val_accuracy: 0.7221 - val_loss: 2.1327\n",
            "Epoch 297/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9992 - loss: 0.0037\n",
            "Epoch 297: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 25ms/step - accuracy: 0.9992 - loss: 0.0037 - val_accuracy: 0.7288 - val_loss: 2.1034\n",
            "Epoch 298/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9995 - loss: 0.0047\n",
            "Epoch 298: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.9995 - loss: 0.0047 - val_accuracy: 0.7279 - val_loss: 2.0984\n",
            "Epoch 299/300\n",
            "\u001b[1m259/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9998 - loss: 0.0032\n",
            "Epoch 299: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.9998 - loss: 0.0032 - val_accuracy: 0.7240 - val_loss: 2.1087\n",
            "Epoch 300/300\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9999 - loss: 0.0037\n",
            "Epoch 300: val_loss did not improve from 0.79413\n",
            "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 25ms/step - accuracy: 0.9999 - loss: 0.0037 - val_accuracy: 0.7260 - val_loss: 2.0978\n"
          ]
        }
      ],
      "source": [
        "hist = model.fit(train_X, train_Y, epochs = EPOCHS, batch_size = BS, validation_data = (val_X, val_Y), callbacks = [checkpoint])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "OSVi9ZFh2CAB"
      },
      "outputs": [],
      "source": [
        "with open('history_model', 'wb') as file:\n",
        "    p.dump(hist.history, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "r0Xih05m2HHB"
      },
      "outputs": [],
      "source": [
        "with open('history_model', 'rb') as file:\n",
        "    his = p.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vpZ1l63w2IjU",
        "outputId": "52dd4a3e-8d21-4b50-88c6-7a9f006a1ce3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"6012c551-2b84-47a9-93d3-8d6f5058e3f3\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"6012c551-2b84-47a9-93d3-8d6f5058e3f3\")) {                    Plotly.newPlot(                        \"6012c551-2b84-47a9-93d3-8d6f5058e3f3\",                        [{\"line\":{\"color\":\"blue\",\"width\":2},\"mode\":\"lines\",\"name\":\"loss\",\"y\":[1.4062849283218384,1.3887958526611328,1.3811744451522827,1.3673847913742065,1.357731819152832,1.3434746265411377,1.3397396802902222,1.320701241493225,1.305495023727417,1.2776750326156616,1.2662302255630493,1.2343684434890747,1.206713318824768,1.1802103519439697,1.1346851587295532,1.0958234071731567,1.0566400289535522,1.022241473197937,0.9838833808898926,0.9530739188194275,0.9170413017272949,0.8942734003067017,0.8549570441246033,0.815555989742279,0.8021277189254761,0.7700610160827637,0.7398970127105713,0.7261009216308594,0.6930379867553711,0.654139518737793,0.6364599466323853,0.6108437776565552,0.5869443416595459,0.5592971444129944,0.5424081087112427,0.5121879577636719,0.4944550693035126,0.4726696312427521,0.4524679481983185,0.4348667562007904,0.4133862853050232,0.40647396445274353,0.38051027059555054,0.36458641290664673,0.35439756512641907,0.34055203199386597,0.3345373570919037,0.3007209002971649,0.2912454605102539,0.2842828333377838,0.2634344696998596,0.2555033266544342,0.23948055505752563,0.2334376722574234,0.22792290151119232,0.21118152141571045,0.20874114334583282,0.19408726692199707,0.18558210134506226,0.1829601377248764,0.17710542678833008,0.16255144774913788,0.16585823893547058,0.15353158116340637,0.14848394691944122,0.14059454202651978,0.1318039447069168,0.14161600172519684,0.12851960957050323,0.12350353598594666,0.12381993979215622,0.1217072606086731,0.11277076601982117,0.10283531993627548,0.10559776425361633,0.09601108729839325,0.09761285036802292,0.09375274181365967,0.08261337876319885,0.08604510128498077,0.08326160162687302,0.07974753528833389,0.08007457852363586,0.07591436803340912,0.07437357306480408,0.07174690067768097,0.06986156851053238,0.07283579558134079,0.0678618922829628,0.05939985811710358,0.05913408473134041,0.05599024519324303,0.05928601697087288,0.059517648071050644,0.05194571614265442,0.053564224392175674,0.054557524621486664,0.046340521425008774,0.04992237314581871,0.0480535514652729,0.051066797226667404,0.043382834643125534,0.042728133499622345,0.04489479586482048,0.039974506944417953,0.04308620095252991,0.04347947984933853,0.04080045223236084,0.03843804448843002,0.03785037621855736,0.035186491906642914,0.0384284183382988,0.036614418029785156,0.03014974109828472,0.0329965278506279,0.03309774771332741,0.03028913028538227,0.03097451664507389,0.03470354899764061,0.03283292055130005,0.02685968019068241,0.03326631337404251,0.02926374226808548,0.027555491775274277,0.025861740112304688,0.02968676947057247,0.02755051851272583,0.031136592850089073,0.02420642226934433,0.0252074021846056,0.02351951226592064,0.021507710218429565,0.021733811125159264,0.02452821098268032,0.01980200968682766,0.02397484891116619,0.020276715978980064,0.019605765119194984,0.021386463195085526,0.019457021728157997,0.02078106626868248,0.018755372613668442,0.01858760230243206,0.020033840090036392,0.017526274546980858,0.019541814923286438,0.01838167943060398,0.0164826437830925,0.01821139082312584,0.020264025777578354,0.015400640666484833,0.01749657467007637,0.015202908776700497,0.013386289589107037,0.01356507558375597,0.017488649114966393,0.01829703524708748,0.013285285793244839,0.01539390068501234,0.011571593582630157,0.013794888742268085,0.012265530414879322,0.016279399394989014,0.01237435732036829,0.01174321398139,0.014494131319224834,0.011406718753278255,0.01124250516295433,0.013338240794837475,0.012730579823255539,0.013963419012725353,0.013216875493526459,0.014996850863099098,0.011207126080989838,0.010150511749088764,0.01112265046685934,0.010006159543991089,0.010815813206136227,0.010540331713855267,0.017628515139222145,0.01275471318513155,0.010996861383318901,0.011677781119942665,0.008217193186283112,0.008764490485191345,0.009195497259497643,0.014007257297635078,0.009022139012813568,0.009354237467050552,0.011446342803537846,0.008545038290321827,0.012018845416605473,0.011529258452355862,0.009564568288624287,0.007863055914640427,0.00834585726261139,0.008374110795557499,0.00912080891430378,0.009129389189183712,0.008977564051747322,0.007816275581717491,0.007539613638073206,0.008339375257492065,0.006811375264078379,0.006769124884158373,0.007917127572000027,0.00876891240477562,0.005875115282833576,0.008217096328735352,0.005535684060305357,0.006225422024726868,0.0067619383335113525,0.008640218526124954,0.007876415736973286,0.006418899167329073,0.007043867837637663,0.006663040723651648,0.008992969058454037,0.006210570689290762,0.008035283535718918,0.008758599869906902,0.006430726498365402,0.005168881732970476,0.004854839760810137,0.007973999716341496,0.004833287093788385,0.007405632641166449,0.004863609094172716,0.006677927449345589,0.0067761121317744255,0.00593516044318676,0.006966599728912115,0.006638956256210804,0.0048898751847445965,0.0066385758109390736,0.005848145578056574,0.007150076329708099,0.009497222490608692,0.0059921895153820515,0.006005075294524431,0.006358861457556486,0.00593096949160099,0.004495101980865002,0.004066883586347103,0.004745597019791603,0.0037842055317014456,0.0055335215292871,0.0051039052195847034,0.010697409510612488,0.006649866234511137,0.0051224809139966965,0.005955301690846682,0.005252780858427286,0.004162226337939501,0.0041777100414037704,0.0054753427393734455,0.003365818876773119,0.004848823416978121,0.00559393921867013,0.003837033174932003,0.00515464274212718,0.003597807139158249,0.009311889298260212,0.00710311159491539,0.005463453009724617,0.005111773032695055,0.0034267983864992857,0.004411389585584402,0.004717283882200718,0.00403728848323226,0.0028453238774091005,0.003598756855353713,0.00442107766866684,0.004696907475590706,0.005048176273703575,0.0037225456908345222,0.004105887841433287,0.004684275947511196,0.004877748433500528,0.003876626491546631,0.00591189693659544,0.005203985143452883,0.004497780930250883,0.004321422427892685,0.004408557433634996,0.006623940076678991,0.004874841775745153,0.0036165614146739244,0.003983919508755207,0.0038306917995214462,0.0044915867038071156,0.0039644986391067505,0.0030954598914831877,0.0039654443971812725,0.004780472721904516,0.004969015251845121,0.005574537441134453,0.004167131148278713,0.004011743236333132,0.003342210780829191],\"type\":\"scatter\"},{\"line\":{\"color\":\"red\",\"width\":2},\"mode\":\"lines\",\"name\":\"val_loss\",\"y\":[1.3844419717788696,1.3771618604660034,1.364267349243164,1.35448157787323,1.3458788394927979,1.334441900253296,1.3225399255752563,1.309224009513855,1.2949061393737793,1.2758044004440308,1.2553174495697021,1.23190176486969,1.2077231407165527,1.186102032661438,1.1516283750534058,1.1253958940505981,1.0960732698440552,1.0937824249267578,1.0453733205795288,1.0259599685668945,1.0050549507141113,1.0209970474243164,0.9661073684692383,0.9778117537498474,0.9350815415382385,0.9388254284858704,0.9053793549537659,0.9009239673614502,0.8805708289146423,0.8632486462593079,0.8529912829399109,0.8442690968513489,0.8391240835189819,0.8786799907684326,0.8218644857406616,0.8155180215835571,0.8101840019226074,0.8118559122085571,0.8006365895271301,0.8035860657691956,0.800952672958374,0.8348972797393799,0.7941276431083679,0.8520826101303101,0.8052778244018555,0.8040297627449036,0.8219720125198364,0.847165048122406,0.8265010714530945,0.8181406259536743,0.8275499939918518,0.8168569207191467,0.854565441608429,0.8351612687110901,0.8505330085754395,0.8626158237457275,0.8426189422607422,0.8558181524276733,0.8761616945266724,0.8831096887588501,0.8834603428840637,0.8729473948478699,0.8941202759742737,0.8903539180755615,0.8863463997840881,0.9017676711082458,0.8981785774230957,0.9172590374946594,0.9198272824287415,0.9363921284675598,0.934106707572937,0.9666571021080017,1.0055668354034424,0.9558114409446716,0.9743316769599915,0.9626624584197998,0.9890130758285522,0.9858910441398621,1.0127556324005127,1.0225173234939575,1.0081168413162231,1.011741042137146,1.0128265619277954,1.0502420663833618,1.056367039680481,1.0686652660369873,1.1047402620315552,1.0650224685668945,1.0617483854293823,1.0635000467300415,1.078230381011963,1.1222946643829346,1.0924923419952393,1.1233679056167603,1.1001967191696167,1.1095906496047974,1.1253336668014526,1.1206974983215332,1.134777307510376,1.1348379850387573,1.1407403945922852,1.156282901763916,1.169636845588684,1.1720961332321167,1.1637614965438843,1.1628038883209229,1.1684478521347046,1.1900275945663452,1.202420949935913,1.2070064544677734,1.1957807540893555,1.210204005241394,1.2361034154891968,1.2418856620788574,1.2394660711288452,1.242293357849121,1.2643251419067383,1.2932014465332031,1.2980817556381226,1.2793998718261719,1.2736440896987915,1.297695517539978,1.3306769132614136,1.3072248697280884,1.3444994688034058,1.3292765617370605,1.3326261043548584,1.353655219078064,1.346718430519104,1.3523062467575073,1.3945256471633911,1.3734731674194336,1.36728835105896,1.3941092491149902,1.3891834020614624,1.4073421955108643,1.413443922996521,1.4373353719711304,1.450706124305725,1.5026081800460815,1.4611308574676514,1.458752155303955,1.5097614526748657,1.4673625230789185,1.452165961265564,1.52315354347229,1.4735405445098877,1.5375256538391113,1.5361723899841309,1.4915518760681152,1.4961934089660645,1.4990845918655396,1.5307354927062988,1.5005394220352173,1.5095165967941284,1.5353209972381592,1.5258870124816895,1.5461466312408447,1.5337992906570435,1.5470539331436157,1.551017165184021,1.5795567035675049,1.612945318222046,1.5468239784240723,1.5979256629943848,1.6259409189224243,1.6014937162399292,1.6176573038101196,1.603521466255188,1.6013013124465942,1.686897873878479,1.6179057359695435,1.640047311782837,1.6220840215682983,1.6449106931686401,1.631131649017334,1.6323448419570923,1.6184226274490356,1.615193247795105,1.6517163515090942,1.663069486618042,1.832428216934204,1.6590343713760376,1.6563085317611694,1.6585367918014526,1.7003257274627686,1.9131083488464355,1.6995832920074463,1.701633334159851,1.7028651237487793,1.7513961791992188,1.7149243354797363,1.7146494388580322,1.727774739265442,1.7516779899597168,1.7264598608016968,1.769371747970581,1.7545100450515747,1.7628669738769531,1.7773911952972412,1.7708207368850708,1.7894246578216553,1.732800006866455,1.8809562921524048,1.759745717048645,1.84663724899292,1.8071643114089966,1.7956682443618774,1.8025168180465698,1.859956979751587,1.8993302583694458,1.8598549365997314,1.9151744842529297,1.874411940574646,1.8400936126708984,1.7969906330108643,1.8407297134399414,1.8443506956100464,1.8498786687850952,1.8554140329360962,1.8756599426269531,1.8633663654327393,1.846166968345642,1.9143351316452026,1.8852020502090454,1.9174537658691406,1.903946042060852,1.8985668420791626,1.8992348909378052,2.103825092315674,1.889251708984375,2.0049471855163574,1.9163310527801514,1.8914086818695068,2.209512710571289,1.9138092994689941,1.8661683797836304,1.9037803411483765,2.0126495361328125,1.9148398637771606,1.949941635131836,1.9301596879959106,1.9370392560958862,1.9426469802856445,1.90523362159729,1.9504797458648682,1.936218500137329,1.9571329355239868,1.959850788116455,1.9480078220367432,1.9621750116348267,1.9792156219482422,1.9969801902770996,1.97674560546875,1.96216881275177,1.9659309387207031,1.9672267436981201,1.9916996955871582,2.010573625564575,1.9793628454208374,2.041517734527588,2.009233236312866,2.1182637214660645,2.006258964538574,2.021758794784546,2.0518977642059326,1.998718023300171,2.063890218734741,2.0136678218841553,2.0239856243133545,2.0454459190368652,2.0638041496276855,2.0368573665618896,2.2204198837280273,2.0368056297302246,2.043144702911377,2.0357859134674072,2.021047353744507,2.0988457202911377,2.0791854858398438,2.148756742477417,2.109253168106079,2.0727570056915283,2.1003525257110596,2.0662031173706055,2.1073684692382812,2.055525064468384,2.0359060764312744,2.037705183029175,2.070115566253662,2.062852382659912,2.084554672241211,2.264989137649536,2.0484163761138916,2.0966200828552246,2.1327030658721924,2.103381633758545,2.0983943939208984,2.108666181564331,2.0977885723114014],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Loss\"},\"xaxis\":{\"title\":{\"text\":\"epochs\"}},\"yaxis\":{\"title\":{\"text\":\"\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('6012c551-2b84-47a9-93d3-8d6f5058e3f3');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "h1 = go.Scatter(y=his['loss'],\n",
        "                    mode=\"lines\", line=dict(\n",
        "                    width=2,\n",
        "                    color='blue'),\n",
        "                    name=\"loss\"\n",
        "                   )\n",
        "h2 = go.Scatter(y=his['val_loss'],\n",
        "                    mode=\"lines\", line=dict(\n",
        "                    width=2,\n",
        "                    color='red'),\n",
        "                    name=\"val_loss\"\n",
        "                   )\n",
        "\n",
        "data = [h1,h2]\n",
        "layout1 = go.Layout(title='Loss',\n",
        "                   xaxis=dict(title='epochs'),\n",
        "                   yaxis=dict(title=''))\n",
        "fig1 = go.Figure(data = data, layout=layout1)\n",
        "fig1.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZS3hHUrj2KR8",
        "outputId": "722892e8-288e-40c8-8a52-ce7ef849ebce"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"488da92b-cfbb-4fc5-8749-adacdef6f453\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"488da92b-cfbb-4fc5-8749-adacdef6f453\")) {                    Plotly.newPlot(                        \"488da92b-cfbb-4fc5-8749-adacdef6f453\",                        [{\"line\":{\"color\":\"blue\",\"width\":2},\"mode\":\"lines\",\"name\":\"acc\",\"y\":[0.2718749940395355,0.27572116255760193,0.29326921701431274,0.30288460850715637,0.31850960850715637,0.34350961446762085,0.3375000059604645,0.3716346025466919,0.38749998807907104,0.4057692289352417,0.42067307233810425,0.44062501192092896,0.45817306637763977,0.48990383744239807,0.5115384459495544,0.529567301273346,0.5572115182876587,0.5653846263885498,0.5930288434028625,0.6100961565971375,0.628125011920929,0.6382211446762085,0.6552884578704834,0.6730769276618958,0.6899038553237915,0.701442301273346,0.7098557949066162,0.7185096144676208,0.7372596263885498,0.7584134340286255,0.7557692527770996,0.7737980484962463,0.7973557710647583,0.8040865659713745,0.8137019276618958,0.8300480842590332,0.8399038314819336,0.8430288434028625,0.8524038195610046,0.8675480484962463,0.8735576868057251,0.8788461685180664,0.8911057710647583,0.8966346383094788,0.9009615182876587,0.90625,0.9009615182876587,0.9274038672447205,0.920192301273346,0.9298076629638672,0.9362980723381042,0.9353365302085876,0.9413461685180664,0.940625011920929,0.9449519515037537,0.9516826868057251,0.9502403736114502,0.9581730961799622,0.9557692408561707,0.9605769515037537,0.9576923251152039,0.9661057591438293,0.9603365659713745,0.9658653736114502,0.9663461446762085,0.9699519276618958,0.9733173251152039,0.9697115421295166,0.9723557829856873,0.9730769395828247,0.973557710647583,0.9725961685180664,0.9762019515037537,0.9800480604171753,0.9778845906257629,0.979567289352417,0.9829326868057251,0.9841346144676208,0.987500011920929,0.984375,0.9853365421295166,0.9870192408561707,0.9836538434028625,0.9872596263885498,0.9879807829856873,0.987500011920929,0.9882211685180664,0.986057698726654,0.9879807829856873,0.9896634817123413,0.9908654093742371,0.9915865659713745,0.9903846383094788,0.9906250238418579,0.9927884340286255,0.9915865659713745,0.9896634817123413,0.9942307472229004,0.9915865659713745,0.9927884340286255,0.9911057949066162,0.9942307472229004,0.9937499761581421,0.9937499761581421,0.995192289352417,0.9942307472229004,0.9906250238418579,0.9935095906257629,0.9937499761581421,0.9947115182876587,0.9949519038200378,0.9944711327552795,0.995192289352417,0.9971153736114502,0.995192289352417,0.9956730604171753,0.9959134459495544,0.9959134459495544,0.9937499761581421,0.9959134459495544,0.9966346025466919,0.9949519038200378,0.9954326748847961,0.996874988079071,0.996874988079071,0.9959134459495544,0.9963942170143127,0.9947115182876587,0.9973557591438293,0.9963942170143127,0.9971153736114502,0.9980769157409668,0.9971153736114502,0.9949519038200378,0.9971153736114502,0.9959134459495544,0.9961538314819336,0.9973557591438293,0.9973557591438293,0.9971153736114502,0.9971153736114502,0.9966346025466919,0.9980769157409668,0.9973557591438293,0.9978365302085876,0.9971153736114502,0.9963942170143127,0.9978365302085876,0.9966346025466919,0.9954326748847961,0.9980769157409668,0.9971153736114502,0.9978365302085876,0.9992788434028625,0.998317301273346,0.9973557591438293,0.9971153736114502,0.9985576868057251,0.998317301273346,0.9995192289352417,0.9985576868057251,0.9987980723381042,0.9971153736114502,0.9985576868057251,0.9997596144676208,0.9978365302085876,0.9990384578704834,0.9985576868057251,0.9980769157409668,0.998317301273346,0.9971153736114502,0.9975961446762085,0.9971153736114502,0.9985576868057251,0.9987980723381042,0.9985576868057251,0.9980769157409668,0.9985576868057251,0.9987980723381042,0.9963942170143127,0.9971153736114502,0.9990384578704834,0.9985576868057251,0.9997596144676208,0.9992788434028625,0.9990384578704834,0.9975961446762085,0.9985576868057251,0.9987980723381042,0.9980769157409668,0.9990384578704834,0.9971153736114502,0.998317301273346,0.9987980723381042,0.9990384578704834,0.9992788434028625,0.9992788434028625,0.9985576868057251,0.9980769157409668,0.9987980723381042,0.9995192289352417,0.9992788434028625,0.9990384578704834,0.9997596144676208,0.9990384578704834,0.9995192289352417,0.9987980723381042,0.9995192289352417,0.9990384578704834,1.0,0.9997596144676208,0.9995192289352417,0.9990384578704834,0.9987980723381042,0.9990384578704834,0.9992788434028625,0.9990384578704834,0.9987980723381042,0.9992788434028625,0.9997596144676208,0.9980769157409668,0.9992788434028625,1.0,0.9997596144676208,0.9987980723381042,1.0,0.9992788434028625,0.9995192289352417,0.9995192289352417,0.9987980723381042,0.9987980723381042,0.9987980723381042,0.9997596144676208,0.9997596144676208,0.9987980723381042,0.9990384578704834,0.9987980723381042,0.9973557591438293,0.9990384578704834,0.9990384578704834,0.9992788434028625,0.9995192289352417,0.9995192289352417,0.9995192289352417,0.9995192289352417,0.9997596144676208,0.9995192289352417,0.9995192289352417,0.9971153736114502,0.9987980723381042,0.9997596144676208,0.9990384578704834,0.9995192289352417,0.9997596144676208,0.9997596144676208,0.9990384578704834,1.0,0.9997596144676208,0.9992788434028625,0.9997596144676208,0.9995192289352417,0.9997596144676208,0.9975961446762085,0.998317301273346,0.9995192289352417,0.9990384578704834,0.9997596144676208,0.9990384578704834,0.9992788434028625,0.9997596144676208,1.0,0.9997596144676208,0.9992788434028625,0.9990384578704834,0.9995192289352417,0.9997596144676208,1.0,0.9997596144676208,0.9995192289352417,0.9990384578704834,0.9995192289352417,0.9992788434028625,0.9992788434028625,0.9992788434028625,0.9992788434028625,0.998317301273346,0.9995192289352417,0.9997596144676208,0.9992788434028625,0.9997596144676208,0.9995192289352417,0.9997596144676208,1.0,1.0,0.9992788434028625,0.9992788434028625,0.998317301273346,0.9995192289352417,0.9995192289352417,0.9997596144676208],\"type\":\"scatter\"},{\"line\":{\"color\":\"red\",\"width\":2},\"mode\":\"lines\",\"name\":\"val_acc\",\"y\":[0.30192306637763977,0.3201923072338104,0.32692307233810425,0.3384615480899811,0.35961538553237915,0.36538460850715637,0.3769230842590332,0.39615383744239807,0.4057692289352417,0.42211538553237915,0.4355769157409668,0.4384615421295166,0.4692307710647583,0.4634615480899811,0.491346150636673,0.47980770468711853,0.4971153736114502,0.5221154093742371,0.5490384697914124,0.5519230961799622,0.5701923370361328,0.5596153736114502,0.5951923131942749,0.5846154093742371,0.6038461327552795,0.5942307710647583,0.6230769157409668,0.6163461804389954,0.629807710647583,0.6509615182876587,0.6682692170143127,0.6567307710647583,0.6596153974533081,0.6653845906257629,0.6817307472229004,0.7009615302085876,0.6971153616905212,0.6990384459495544,0.7067307829856873,0.7067307829856873,0.7057692408561707,0.6759615540504456,0.7124999761581421,0.6778846383094788,0.704807698726654,0.7096154093742371,0.7086538672447205,0.6846153736114502,0.7067307829856873,0.7153846025466919,0.7182692289352417,0.7182692289352417,0.7173076868057251,0.7105769515037537,0.7057692408561707,0.7067307829856873,0.7173076868057251,0.7201923131942749,0.7134615182876587,0.7105769515037537,0.7192307710647583,0.7221153974533081,0.7115384340286255,0.7230769395828247,0.7259615659713745,0.7163461446762085,0.7278845906257629,0.7211538553237915,0.7317307591438293,0.7211538553237915,0.7278845906257629,0.7105769515037537,0.7105769515037537,0.7221153974533081,0.7240384817123413,0.7336538434028625,0.7201923131942749,0.7240384817123413,0.7153846025466919,0.7173076868057251,0.7307692170143127,0.7211538553237915,0.7250000238418579,0.7153846025466919,0.7173076868057251,0.7144230604171753,0.7067307829856873,0.7182692289352417,0.7250000238418579,0.7259615659713745,0.7221153974533081,0.7211538553237915,0.7173076868057251,0.7221153974533081,0.7240384817123413,0.7259615659713745,0.7211538553237915,0.7250000238418579,0.7307692170143127,0.7173076868057251,0.7288461327552795,0.7211538553237915,0.7201923131942749,0.7240384817123413,0.7240384817123413,0.7336538434028625,0.7259615659713745,0.7230769395828247,0.7259615659713745,0.7317307591438293,0.7307692170143127,0.7278845906257629,0.7259615659713745,0.7250000238418579,0.7250000238418579,0.7317307591438293,0.7269230484962463,0.7250000238418579,0.7221153974533081,0.732692301273346,0.7307692170143127,0.7317307591438293,0.7307692170143127,0.7346153855323792,0.7298076748847961,0.7288461327552795,0.7317307591438293,0.732692301273346,0.7336538434028625,0.7317307591438293,0.7365384697914124,0.7336538434028625,0.7365384697914124,0.7432692050933838,0.7317307591438293,0.7307692170143127,0.7384615540504456,0.7230769395828247,0.7355769276618958,0.7028846144676208,0.737500011920929,0.7307692170143127,0.7250000238418579,0.7346153855323792,0.7346153855323792,0.7269230484962463,0.7173076868057251,0.7278845906257629,0.7336538434028625,0.7336538434028625,0.7221153974533081,0.7288461327552795,0.7278845906257629,0.7336538434028625,0.7269230484962463,0.737500011920929,0.7240384817123413,0.7278845906257629,0.732692301273346,0.7250000238418579,0.732692301273346,0.7173076868057251,0.7259615659713745,0.7250000238418579,0.7269230484962463,0.7211538553237915,0.7230769395828247,0.7259615659713745,0.7019230723381042,0.7230769395828247,0.7057692408561707,0.7250000238418579,0.7278845906257629,0.7307692170143127,0.7278845906257629,0.7269230484962463,0.7288461327552795,0.7298076748847961,0.7211538553237915,0.7288461327552795,0.7134615182876587,0.7105769515037537,0.7288461327552795,0.7240384817123413,0.7230769395828247,0.7269230484962463,0.6884615421295166,0.7182692289352417,0.7240384817123413,0.7192307710647583,0.7153846025466919,0.7230769395828247,0.7134615182876587,0.7124999761581421,0.7173076868057251,0.7201923131942749,0.7173076868057251,0.7221153974533081,0.7240384817123413,0.7278845906257629,0.7192307710647583,0.7269230484962463,0.7144230604171753,0.7221153974533081,0.7192307710647583,0.7182692289352417,0.7230769395828247,0.7192307710647583,0.7201923131942749,0.7221153974533081,0.7038461565971375,0.7134615182876587,0.7192307710647583,0.7144230604171753,0.7250000238418579,0.7192307710647583,0.7317307591438293,0.7250000238418579,0.7298076748847961,0.7201923131942749,0.7221153974533081,0.7288461327552795,0.7288461327552795,0.7250000238418579,0.7211538553237915,0.7144230604171753,0.7278845906257629,0.7269230484962463,0.7221153974533081,0.7067307829856873,0.7250000238418579,0.6990384459495544,0.7269230484962463,0.7173076868057251,0.6894230842590332,0.7192307710647583,0.7124999761581421,0.7221153974533081,0.7019230723381042,0.7240384817123413,0.7259615659713745,0.7240384817123413,0.7230769395828247,0.7240384817123413,0.7182692289352417,0.7192307710647583,0.7182692289352417,0.7211538553237915,0.7038461565971375,0.7115384340286255,0.7230769395828247,0.7240384817123413,0.7201923131942749,0.7201923131942749,0.7230769395828247,0.7211538553237915,0.7221153974533081,0.7230769395828247,0.7201923131942749,0.7173076868057251,0.7201923131942749,0.7230769395828247,0.7163461446762085,0.7221153974533081,0.7201923131942749,0.7192307710647583,0.7269230484962463,0.7144230604171753,0.7163461446762085,0.7240384817123413,0.7230769395828247,0.699999988079071,0.7288461327552795,0.7067307829856873,0.7240384817123413,0.7192307710647583,0.7221153974533081,0.7230769395828247,0.7182692289352417,0.7269230484962463,0.7144230604171753,0.7211538553237915,0.7250000238418579,0.7240384817123413,0.7240384817123413,0.7307692170143127,0.7288461327552795,0.7307692170143127,0.7240384817123413,0.7278845906257629,0.7230769395828247,0.7250000238418579,0.7230769395828247,0.7221153974533081,0.7182692289352417,0.7221153974533081,0.7288461327552795,0.7278845906257629,0.7240384817123413,0.7259615659713745],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Accuracy\"},\"xaxis\":{\"title\":{\"text\":\"epochs\"}},\"yaxis\":{\"title\":{\"text\":\"\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('488da92b-cfbb-4fc5-8749-adacdef6f453');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "h1 = go.Scatter(y=his['accuracy'],\n",
        "                    mode=\"lines\", line=dict(\n",
        "                    width=2,\n",
        "                    color='blue'),\n",
        "                    name=\"acc\"\n",
        "                   )\n",
        "h2 = go.Scatter(y=his['val_accuracy'],\n",
        "                    mode=\"lines\", line=dict(\n",
        "                    width=2,\n",
        "                    color='red'),\n",
        "                    name=\"val_acc\"\n",
        "                   )\n",
        "\n",
        "data = [h1,h2]\n",
        "layout1 = go.Layout(title='Accuracy',\n",
        "                   xaxis=dict(title='epochs'),\n",
        "                   yaxis=dict(title=''))\n",
        "fig1 = go.Figure(data = data, layout=layout1)\n",
        "fig1.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "iKQI3Jar2Qah",
        "outputId": "201fd7b8-cca3-4227-f94f-899f5deed218"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">231</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">980,224</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">260</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m231\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m980,224\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │         \u001b[38;5;34m263,168\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m32,896\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │             \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │             \u001b[38;5;34m260\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,854,926</span> (14.71 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,854,926\u001b[0m (14.71 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,284,932</span> (4.90 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,284,932\u001b[0m (4.90 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> (512.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m128\u001b[0m (512.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,569,866</span> (9.80 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2,569,866\u001b[0m (9.80 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "predict_model = load_model(filename)\n",
        "predict_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "XmjHwrTs2S0l",
        "outputId": "7b1a9d89-2cd9-4c48-c6ad-0b98b101e15d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validate loss: 0.7941276431083679\n",
            "Validate accuracy: 0.7124999761581421\n"
          ]
        }
      ],
      "source": [
        "score = predict_model.evaluate(val_X, val_Y, verbose=0)\n",
        "print('Validate loss:', score[0])\n",
        "print('Validate accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nJZ2WjSN2Vqr",
        "outputId": "867f865e-18fb-463d-8764-a66665b92013"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(1040,)"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predicted_classes = np.argmax(predict_model.predict(val_X), axis=-1)\n",
        "predicted_classes.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NV65aUtF2Zbp",
        "outputId": "62dba683-752e-4534-de30-099a9f837bcb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0. 1. 0. 0.]\n",
            "1\n"
          ]
        }
      ],
      "source": [
        "y_true = np.argmax(val_Y,axis = 1)\n",
        "print(val_Y[0])\n",
        "print(y_true[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGkRaKr4OYNt"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "G9CLJBQn2cNC"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_true, predicted_classes)\n",
        "np.savetxt(\"confusion_matrix.csv\", cm, delimiter=\",\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mk2zFmQv2edv",
        "outputId": "df8934ea-4e3f-40ef-8a93-d5534106e5df"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 2000x1400 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df_cm = pd.DataFrame(cm, range(4), range(4))\n",
        "plt.figure(figsize=(20,14))\n",
        "sn.set(font_scale=1.2) # for label size\n",
        "sn.heatmap(df_cm, annot=True, annot_kws={\"size\": 14}, fmt='g') # for num predict size\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3l_zqasU2gf1"
      },
      "outputs": [],
      "source": [
        "label_dict = output_tokenizer.word_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ne6s_kM72i4r"
      },
      "outputs": [],
      "source": [
        "label = [key for key, value in label_dict.items()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ntBX5BSK2kSd",
        "outputId": "362f27fe-a721-484a-fa2f-58ae5fb1044a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         hig     0.7955    0.8231    0.8091       260\n",
            "         pos     0.7276    0.6885    0.7075       260\n",
            "         neg     0.6128    0.5538    0.5818       260\n",
            "         bly     0.7034    0.7846    0.7418       260\n",
            "\n",
            "    accuracy                         0.7125      1040\n",
            "   macro avg     0.7098    0.7125    0.7101      1040\n",
            "weighted avg     0.7098    0.7125    0.7101      1040\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_true, predicted_classes, target_names=label, digits=4))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}